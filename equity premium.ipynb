{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel files are read and a ticker column is added to each sheet\n",
    "\n",
    "repertoire = \"data\" \n",
    "dataframes_dict = {}\n",
    "\n",
    "for fichier in os.listdir(repertoire): \n",
    "    chemin_complet = os.path.join(repertoire, fichier)\n",
    "\n",
    "    if fichier.endswith((\".xls\", \".xlsx\")):  \n",
    "        print(f\"File found : {fichier}\")\n",
    "\n",
    "    try:\n",
    "        worksheet = pd.read_excel(chemin_complet, sheet_name=None)\n",
    "\n",
    "        for sheet_name, df in worksheet.items():\n",
    "            if 'Ticker' not in df.columns:\n",
    "                df['Ticker'] = sheet_name  \n",
    "                print(f\"Ticker added to {sheet_name}\")\n",
    "                dataframes_dict[f\"{fichier}_{sheet_name}\"] = df\n",
    "            else:\n",
    "                print(f\"Column 'Ticker' already existed in {fichier}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during the process {fichier} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables are renamed and split by frequency\n",
    "monthly_list = []\n",
    "yearly_list = []\n",
    "quarterly_list = []\n",
    "daily_tot_return_list = []\n",
    "daily_vol_list = [] #two daily lists are created because the start dates differ\n",
    "\n",
    "for name, df in dataframes_dict.items():\n",
    "    rename_map = {\n",
    "        df.columns.values[0]: \"Date.1\",\n",
    "        df.columns.values[1]: \"Total_Assets\",\n",
    "        df.columns.values[2]: \"Common_Equity\",\n",
    "        df.columns.values[3]: \"Cash_And_Investments\",\n",
    "        df.columns.values[4]: \"R&D_Expenses\",\n",
    "        df.columns.values[5]: \"Inventories\",\n",
    "        df.columns.values[6]: \"Dividends_Paid\",\n",
    "        df.columns.values[7]: \"Gross_Fixed_Assets\",\n",
    "        df.columns.values[8]: \"Income_Before_Extra_Items\",\n",
    "        df.columns.values[9]: \"Sales_Revenue\",\n",
    "        df.columns.values[10]: \"Depreciation_Amortization\",\n",
    "\n",
    "        df.columns.values[12]: \"Date.2\",\n",
    "        df.columns.values[13]: \"Mkt_Cap_Yearly\",\n",
    "        df.columns.values[14]: \"Shares_Outstanding_Yearly\",\n",
    "\n",
    "        df.columns.values[16]: \"Date.3\",\n",
    "        df.columns.values[17]: \"Net_Income\",\n",
    "\n",
    "        df.columns.values[19]: \"Date.4\",\n",
    "        df.columns.values[20]: \"Px_Bid\",\n",
    "        df.columns.values[21]: \"Px_Ask\",\n",
    "        df.columns.values[22]: \"Shares_Outstanding_Monthly\",\n",
    "        df.columns.values[23]: \"Mkt_Cap_Monthly\",\n",
    "\n",
    "        df.columns.values[25]: \"Date.5\",\n",
    "        df.columns.values[26]: \"Px_Last\",\n",
    "\n",
    "        df.columns.values[28]: \"Date.6\",\n",
    "        df.columns.values[29]: \"Volume\",\n",
    "    }\n",
    "\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    try:\n",
    "        df_yearly = df[[\n",
    "            \"Date.1\", \"Total_Assets\", \"Common_Equity\", \"Cash_And_Investments\",\n",
    "            \"R&D_Expenses\", \"Inventories\", \"Dividends_Paid\", \"Gross_Fixed_Assets\",\n",
    "            \"Income_Before_Extra_Items\", \"Sales_Revenue\", \"Depreciation_Amortization\",\n",
    "            \"Mkt_Cap_Yearly\", \"Shares_Outstanding_Yearly\"\n",
    "        ]].copy()\n",
    "        \n",
    "        df_quarterly = df[[\"Date.3\", \"Net_Income\"]].copy()\n",
    "       \n",
    "        df_monthly = df[[\n",
    "            \"Date.4\", \"Px_Bid\", \"Px_Ask\", \"Shares_Outstanding_Monthly\", \"Mkt_Cap_Monthly\", \n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_tot_return = df[[\n",
    "            \"Date.5\", \"Px_Last\"\n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_vol= df[[\n",
    "            \"Date.6\", \"Volume\"\n",
    "        ]].copy()\n",
    "        \n",
    "        df_yearly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_monthly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_quarterly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_tot_return['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_vol['Ticker'] = df['Ticker'].iloc[0]\n",
    "        \n",
    "        yearly_list.append(df_yearly)\n",
    "        monthly_list.append(df_monthly)\n",
    "        quarterly_list.append(df_quarterly)\n",
    "        daily_tot_return_list.append(df_daily_tot_return)\n",
    "        daily_vol_list.append(df_daily_vol)\n",
    "        \n",
    "        print(f\"{name} : successful yearly / monthly / quarterly split\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{name} : error during split : {e}\")\n",
    "\n",
    "yearly_df = pd.concat(yearly_list, ignore_index=True)\n",
    "monthly_df = pd.concat(monthly_list, ignore_index=True)\n",
    "quarterly_df = pd.concat(quarterly_list, ignore_index=True)\n",
    "daily_tot_return_df = pd.concat(daily_tot_return_list, ignore_index=True)\n",
    "daily_vol_df = pd.concat(daily_vol_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Type de yearly_df : {type(yearly_df)}\")\n",
    "print(f\"Type de monthly_df : {type(monthly_df)}\")\n",
    "print(f\"Type de daily_tot_return_df : {type(daily_tot_return_df)}\")\n",
    "print(f\"Type de daily_vol_df : {type(daily_vol_df)}\")\n",
    "print(f\"Type de quarterly_df : {type(quarterly_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = {\n",
    "    \"yearly\": yearly_df,\n",
    "    \"quarterly\": quarterly_df,\n",
    "    \"monthly\": monthly_df,\n",
    "    \"daily_tot_return\": daily_tot_return_df,\n",
    "    \"daily_vol\": daily_vol_df\n",
    "}\n",
    "\n",
    "for name, df in lists.items():\n",
    "    #we rename columns starting with \"Date.xxx\" to \"Date\"\n",
    "    df.rename(columns={col: \"Date\" for col in df.columns if col.startswith(\"Date\")}, inplace=True)\n",
    "    \n",
    "    #we convert \"Date\" column to datetime\n",
    "    if \"Date\" in df.columns:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "    \n",
    "    #we convert all other columns to float64 (excluding \"Date\" and \"Ticker\")\n",
    "    for col in df.columns:\n",
    "        if col not in [\"Date\", \"Ticker\"]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(\"float64\")\n",
    "\n",
    "    #display column information for verification\n",
    "    print(f\"--- {name.capitalize()} DataFrame ---\")\n",
    "    print(f\"  - Colonnes et Types:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"    - {col}: {df[col].dtype}\")\n",
    "    print(f\"  - Nombre de lignes: {df.shape[0]}\")\n",
    "    print(f\"  - Nombre de colonnes: {df.shape[1]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN Cells\n",
    "\"\"\"\n",
    "We remove rows where the date column is NaN. When splitting the data by frequency, each row is assigned a ticker.\n",
    "However, because daily data have more rows than other frequencies, the ticker is excessively duplicated in the lower-frequency \n",
    "DataFrames (monthly, quarterly, yearly), leading to rows that are mostly empty.\n",
    "Dropping rows without a date removes these redundancies without any loss of actual data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lists[\"yearly\"] = yearly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"quarterly\"] = quarterly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"monthly\"] = monthly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"daily_vol\"] = daily_vol_df.dropna(subset=[\"Date\"])\n",
    "\n",
    "all_nan_matrices = {}\n",
    "\n",
    "for name, df in lists.items():  \n",
    "    \n",
    "    if \"Ticker\" in df.columns:\n",
    "        #compute the percentage of NaNs per column for each ticker\n",
    "        nan_matrix = df.groupby(\"Ticker\").apply(lambda g: g.isna().mean() * 100)\n",
    "        all_nan_matrices[name] = nan_matrix\n",
    "        print(f\"\\n % Pourcentage de NaN pour {name} :\\n\", nan_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN handling using SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#create an imputer to replace NaNs with the mean\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "for name, df in lists.items():\n",
    "    cols_to_impute = [col for col in df.columns if col not in [\"Date\", \"Ticker\"]]\n",
    "    df.loc[:, cols_to_impute] = imputer.fit_transform(df[cols_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df = lists[\"yearly\"]\n",
    "quarterly_df = lists[\"quarterly\"]\n",
    "monthly_df = lists[\"monthly\"]\n",
    "daily_vol_df = lists[\"daily_vol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly computations    \n",
    "\n",
    "#mkt cap and shares outstanding were extracted with a BDH formula and are expressed in millions so we have to multiply by 10^6\n",
    "yearly_df[\"Mkt_Cap_Yearly\"] = yearly_df[\"Mkt_Cap_Yearly\"] * 1e6\n",
    "yearly_df[\"Shares_Outstanding_Yearly\"] = yearly_df[\"Shares_Outstanding_Yearly\"] * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly computations\n",
    "\n",
    "#asset growth (agr)\n",
    "yearly_df[\"agr\"] = (\n",
    "    yearly_df[\"Total_Assets\"] - yearly_df.groupby(\"Ticker\")[\"Total_Assets\"].shift(1)\n",
    ") / yearly_df.groupby(\"Ticker\")[\"Total_Assets\"].shift(1)\n",
    "\n",
    "\n",
    "#cash productivity (cashpr)\n",
    "yearly_df.loc[:, \"cashpr\"] = (\n",
    "    yearly_df[\"Mkt_Cap_Yearly\"] - yearly_df[\"Common_Equity\"]\n",
    ") / yearly_df[\"Cash_And_Investments\"]\n",
    "\n",
    "\n",
    "#change in inventory (chinv)\n",
    "yearly_df[\"chinv\"] = (\n",
    "    yearly_df[\"Inventories\"] - yearly_df.groupby(\"Ticker\")[\"Inventories\"].shift(1)\n",
    ") / yearly_df[\"Total_Assets\"]\n",
    "\n",
    "\n",
    "\n",
    "#depreciation / Gross Fixed Assets (depr)\n",
    "yearly_df[\"depr\"] = (\n",
    "    yearly_df[\"Depreciation_Amortization\"] / \n",
    "    yearly_df[\"Gross_Fixed_Assets\"]\n",
    ")\n",
    "\n",
    "#dividends to Market Cap (dy)\n",
    "yearly_df.loc[:, \"dy\"] = (\n",
    "    yearly_df[\"Dividends_Paid\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "#earnings to Price (ep)\n",
    "yearly_df.loc[:, \"ep\"] = (\n",
    "    yearly_df[\"Income_Before_Extra_Items\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "#investment to assets (invest)\n",
    "yearly_df.loc[:, \"invest\"] = (\n",
    "    yearly_df.groupby(\"Ticker\")[\"Gross_Fixed_Assets\"].transform(lambda x: x - x.shift(1))\n",
    "    + yearly_df.groupby(\"Ticker\")[\"Inventories\"].transform(lambda x: x - x.shift(1))\n",
    ") / yearly_df.groupby(\"Ticker\")[\"Total_Assets\"].transform(lambda x: x.shift(1))\n",
    "\n",
    "\n",
    "#R&D to Market Value of Equity (rd_mve)\n",
    "yearly_df.loc[:, \"rd_mve\"] = (\n",
    "    yearly_df[\"R&D_Expenses\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "#sales to Price (sp)\n",
    "yearly_df.loc[:, \"sp\"] = (\n",
    "    yearly_df[\"Sales_Revenue\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df.to_excel(\"yearly_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quarterly computations\n",
    "\n",
    "quarterly_df[\"delta_income\"] = (\n",
    "    quarterly_df[\"Net_Income\"] - quarterly_df[\"Net_Income\"].shift(1)\n",
    ")\n",
    "\n",
    "quarterly_df[\"direction\"] = np.sign(quarterly_df[\"delta_income\"])\n",
    "\n",
    "\n",
    "def compute_nincr(direction_series):\n",
    "    nincr = []\n",
    "    count = 0\n",
    "    prev = 0\n",
    "    for d in direction_series:\n",
    "        if d == prev and d != 0:\n",
    "            count += 1\n",
    "        elif d != 0:\n",
    "            count = 1\n",
    "        else:\n",
    "            count = 0\n",
    "        nincr.append(count * d if d != 0 else 0)\n",
    "        prev = d if d != 0 else prev\n",
    "    return nincr\n",
    "\n",
    "quarterly_df[\"nincr\"] = (\n",
    "    quarterly_df.groupby(\"Ticker\")[\"direction\"].transform(compute_nincr)\n",
    ")\n",
    "\n",
    "print(quarterly_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly computations\n",
    "\n",
    "#px_last and volume are needed to compute the monthly covariates\n",
    "\n",
    "#merge for Px_Last\n",
    "monthly_df = monthly_df.merge(\n",
    "    daily_tot_return_df[[\"Date\", \"Ticker\", \"Px_Last\"]],\n",
    "    on=[\"Date\", \"Ticker\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "#merge for Volume\n",
    "monthly_df = monthly_df.merge(\n",
    "    daily_vol_df[[\"Date\", \"Ticker\", \"Volume\"]],\n",
    "    on=[\"Date\", \"Ticker\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "#sort to ensure ffill works correctly\n",
    "monthly_df = monthly_df.sort_values([\"Ticker\", \"Date\"])\n",
    "\n",
    "monthly_df[\"Px_Last\"] = monthly_df.groupby(\"Ticker\")[\"Px_Last\"].ffill()\n",
    "monthly_df[\"Volume\"] = monthly_df.groupby(\"Ticker\")[\"Volume\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly computations\n",
    "\n",
    "#convert date to monthly period si date encore un datatime on convertit sinon on  ne fait rien\n",
    "monthly_df = monthly_df.rename(columns={\"Date\": \"Month\"})\n",
    "\n",
    "if pd.api.types.is_datetime64_any_dtype(monthly_df[\"Month\"]):\n",
    "    monthly_df[\"Month\"] = monthly_df[\"Month\"].dt.to_period(\"M\")\n",
    "\n",
    "#bid-ask spread (baspread)\n",
    "monthly_df.loc[:, \"baspread\"] = (\n",
    "    monthly_df[\"Px_Ask\"] - monthly_df[\"Px_Bid\"]\n",
    ") / ((monthly_df[\"Px_Ask\"] + monthly_df[\"Px_Bid\"]) / 2)\n",
    "\n",
    "\n",
    "#dollar trading volume (dolvol\n",
    "monthly_df.loc[:, \"dolvol\"] = (np.log(\n",
    "    monthly_df.groupby(\"Ticker\")[\"Volume\"].shift(2) * \n",
    "    monthly_df.groupby(\"Ticker\")[\"Px_Last\"].shift(2))\n",
    ")\n",
    "\n",
    "#size (mvel1)\n",
    "monthly_df.loc[:, \"mvel1\"] = np.log(monthly_df[\"Mkt_Cap_Monthly\"]).shift(1)\n",
    "\n",
    "#more complex monthly calculations: maxret, momentums : create a dedicated DataFrame for these computations\n",
    "\n",
    "#convert daily date to monthly period\n",
    "if daily_tot_return_df.index.name == \"Date\":\n",
    "    daily_tot_return_df = daily_tot_return_df.reset_index()\n",
    "\n",
    "daily_tot_return_df[\"Month\"] = daily_tot_return_df[\"Date\"].dt.to_period(\"M\")\n",
    "monthly_calculations_df = daily_tot_return_df[\"Month\"].copy()\n",
    "\n",
    "#daily return computation\n",
    "daily_tot_return_df[\"daily return\"] = (\n",
    "    (daily_tot_return_df[\"Px_Last\"] - daily_tot_return_df.groupby(\"Ticker\")[\"Px_Last\"].transform(\"shift\", 1))\n",
    "    / daily_tot_return_df.groupby(\"Ticker\")[\"Px_Last\"].transform(\"shift\", 1)\n",
    ")   \n",
    "\n",
    "#max return (maxret)\n",
    "maxret_df = (\n",
    "    daily_tot_return_df.groupby([\"Ticker\", \"Month\"])[\"daily return\"]\n",
    "    .max()\n",
    "    .groupby(level=0)\n",
    "    .shift(1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily return\": \"maxret\"})\n",
    ")\n",
    "\n",
    "#return volatility (retvol)\n",
    "retvol_df = (\n",
    "    daily_tot_return_df\n",
    "    .groupby([\"Ticker\", \"Month\"])[\"daily return\"]\n",
    "    .std()\n",
    "    .groupby(level=0)  # level=0 = Ticker\n",
    "    .shift(1)          # shift par Ticker\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily return\": \"retvol\"})\n",
    ")\n",
    "\n",
    "\n",
    "#momentums computations\n",
    "\n",
    "#monthly compounded return computation\n",
    "monthly_return_df = (\n",
    "    daily_tot_return_df.groupby([\"Ticker\", \"Month\"])[\"daily return\"]\n",
    "    .apply(lambda x: (1 + x).prod() - 1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily return\": \"monthly return\"})\n",
    ")\n",
    "\n",
    "#36-month momentum (mom36m)\n",
    "monthly_return_df[\"mom36m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(13)).rolling(window=24, min_periods=24).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "#12-month mommentum (mom12m)\n",
    "monthly_return_df[\"mom12m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(2)).rolling(window=11, min_periods=11).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "#6-month momentum (mom6m)\n",
    "monthly_return_df[\"mom6m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(2)).rolling(window=5, min_periods=5).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "#1-month momentum (mom1m)\n",
    "monthly_return_df[\"mom1m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"].shift(1)\n",
    ")\n",
    "\n",
    "\n",
    "#chmom \n",
    "monthly_return_df[\"chmom\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(1)).rolling(window=6, min_periods=6).apply(np.prod, raw=True) - 1) - \n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(7)).rolling(window=6, min_periods=6).apply(np.prod, raw=True) - 1)\n",
    "\n",
    ")\n",
    "\n",
    "#share turnover (turn)\n",
    "daily_vol_df[\"Date(M)\"] = daily_vol_df[\"Date\"].dt.to_period(\"M\")\n",
    "daily_vol_df[\"Mean_Volume\"] = daily_vol_df.groupby([\"Ticker\", \"Date(M)\"])[\"Volume\"].transform(\"mean\")  \n",
    "\n",
    "turn_df = (\n",
    "    daily_vol_df.groupby([\"Ticker\", \"Date(M)\"])[\"Mean_Volume\"].first().reset_index()\n",
    ")\n",
    "\n",
    "turn_df = turn_df.merge(\n",
    "    monthly_df[[\"Ticker\", \"Month\", \"Shares_Outstanding_Monthly\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"Ticker\", \"Date(M)\"],\n",
    "    right_on=[\"Ticker\", \"Month\"]\n",
    ")\n",
    "\n",
    "turn_df[\"turn\"] = (\n",
    "    turn_df[\"Mean_Volume\"]\n",
    "    .groupby(monthly_df[\"Ticker\"])\n",
    "    .transform(lambda x: x.rolling(window=3, min_periods=3).mean())\n",
    "    / turn_df[\"Shares_Outstanding_Monthly\"]\n",
    ")\n",
    "\n",
    "#merging of all df\n",
    "monthly_calculations_df = (\n",
    "    monthly_return_df\n",
    "    .merge(maxret_df, on=[\"Ticker\", \"Month\"], how=\"left\")\n",
    "    .merge(retvol_df, on=[\"Ticker\", \"Month\"], how=\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(turn_df.head())\n",
    "print(merged_monthly_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_calculations_df[\"Month\"] = pd.PeriodIndex(monthly_calculations_df[\"Month\"], freq=\"M\")\n",
    "\n",
    "merged_monthly_df = monthly_calculations_df.merge(\n",
    "    monthly_df,                 \n",
    "    on=[\"Ticker\", \"Month\"],    \n",
    "    how=\"left\"                  \n",
    ")\n",
    "\n",
    "merged_monthly_df = turn_df[[\"Ticker\", \"Month\", \"turn\"]].merge(\n",
    "    merged_monthly_df,\n",
    "    on=[\"Ticker\", \"Month\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly computations → beta\n",
    "\n",
    "#we need the weekly returns to compute beta\n",
    "if daily_tot_return_df.index.name != \"Date\":\n",
    "    daily_tot_return_df.set_index(\"Date\", inplace=True)\n",
    "    print(\"Index defined on Date\")\n",
    "else:\n",
    "    print(\"Date is already in the index\")\n",
    "\n",
    "\n",
    "weekly_prices = daily_tot_return_df.groupby(\"Ticker\")[\"Px_Last\"].resample(\"W\").last().reset_index()\n",
    "\n",
    "#weekly returns computation\n",
    "weekly_prices[\"weekly_return\"] = (\n",
    "    (weekly_prices[\"Px_Last\"] - weekly_prices.groupby(\"Ticker\")[\"Px_Last\"].transform(\"shift\", 1))\n",
    "    / weekly_prices.groupby(\"Ticker\")[\"Px_Last\"].transform(\"shift\", 1)\n",
    ")   \n",
    "\n",
    "\n",
    "pivot = weekly_prices.pivot(index=\"Date\", columns=\"Ticker\", values=\"weekly_return\") #transposée : 1 ligne par date \n",
    "pivot[\"Market\"] = pivot.mean(axis=1, skipna=True) #moyenne des returns par semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  #since the computation is long, we use tqdm to display a progress bar\n",
    "import statsmodels.api as sm\n",
    "\n",
    "results = []\n",
    "\n",
    "for ticker in tqdm(pivot.columns.drop(\"Market\")):\n",
    "    #we loop over each month, starting 3 years after the first date; freq=\"ME\" since we move month by month\n",
    "    for current_month in pd.date_range(start=pivot.index.min() + pd.DateOffset(years=3), \n",
    "                                       end=pivot.index.max(), freq=\"ME\"):\n",
    "\n",
    "        #current_month is already a timestamp\n",
    "        end_date = current_month - pd.DateOffset(months=1)\n",
    "        start_date = end_date - pd.DateOffset(years=3)\n",
    "\n",
    "        #extract weekly data for this 3-year window, containing the stock and market returns\n",
    "        try:\n",
    "            window = pivot.loc[start_date:end_date, [ticker, \"Market\"]].dropna()\n",
    "        except KeyError:\n",
    "            #fallback if the date does not exist exactly\n",
    "            window = pivot.loc[(pivot.index >= start_date) & (pivot.index <= end_date), [ticker, \"Market\"]].dropna()\n",
    "\n",
    "        #I thought I could remove the if, but apparently not?\n",
    "        if len(window) >= 156:  #156 weeks = 3 years\n",
    "            X = sm.add_constant(window[\"Market\"])  #explicative variable + constant (alpha)\n",
    "            y = window[ticker]  #dependent variable\n",
    "\n",
    "            model = sm.OLS(y, X).fit()  #linear regression with statsmodels\n",
    "            beta = model.params[\"Market\"]  #slope = beta\n",
    "            alpha = model.params[\"const\"]  #intercept = alpha\n",
    "            r_squared = model.rsquared  #model explanatory power\n",
    "            p_value = model.pvalues[\"Market\"] #pvalue of beta\n",
    "\n",
    "            results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Month\": current_month.to_period(\"M\"),\n",
    "                \"Beta\": beta,\n",
    "                \"Alpha\": alpha,\n",
    "                \"R2\": r_squared,\n",
    "                \"p_value\": p_value\n",
    "            })\n",
    "\n",
    "# final DataFrame\n",
    "beta_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df.to_excel(\"beta_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#beta test : are the beta coherent \n",
    "# pvalue, beta, R², alpha → mean\n",
    "beta_cols = [\"Beta\", \"Alpha\", \"R2\", \"p_value\"]\n",
    "beta_means = beta_df[beta_cols].mean()\n",
    "beta_std = beta_df[beta_cols].std()\n",
    "\n",
    "print(\"Standard deviation is:\", beta_std)\n",
    "print(\"Means is:\", beta_means)\n",
    "\n",
    "#beta histogram\n",
    "beta_df[\"Beta\"].hist(bins=30); plt.title(\"Distribution des beta\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta squared\n",
    "beta_df[\"Beta_squared\"] = beta_df[\"Beta\"] ** 2\n",
    "\n",
    "#merge with merge_monthly_df\n",
    "beta_cols = beta_df[[\"Ticker\", \"Month\", \"Beta\", \"Beta_squared\"]]\n",
    "merged_monthly_df = (\n",
    "    merged_monthly_df                  # ← celui que tu as obtenu plus haut\n",
    "    .merge(beta_cols, on=[\"Ticker\", \"Month\"], how=\"left\")\n",
    ")\n",
    "\n",
    "print(merged_monthly_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idiovol computation \n",
    "\n",
    "pivot[\"Market\"] = pivot.mean(axis=1, skipna=True)\n",
    "\n",
    "idio_vol_results = []\n",
    "\n",
    "for ticker in tqdm(pivot.columns.drop(\"Market\")):\n",
    "    for current_month in pd.date_range(start=pivot.index.min() + pd.DateOffset(years=3),\n",
    "                                       end=pivot.index.max(), freq=\"ME\"):\n",
    "\n",
    "        end_date = current_month\n",
    "        start_date = end_date - pd.DateOffset(years=3)\n",
    "\n",
    "        try:\n",
    "            window = pivot.loc[start_date:end_date, [ticker, \"Market\"]].dropna()\n",
    "        except KeyError:\n",
    "            window = pivot.loc[(pivot.index >= start_date) & \n",
    "                                      (pivot.index <= end_date), [ticker, \"Market\"]].dropna()\n",
    "\n",
    "        if len(window) >= 52:  # At least one year of data\n",
    "            X = sm.add_constant(window[\"Market\"])\n",
    "            y = window[ticker]\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            residuals = model.resid\n",
    "            idio_std = np.std(residuals)\n",
    "\n",
    "            idio_vol_results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Month\": current_month.to_period(\"M\"),\n",
    "                \"Idiovol\": idio_std\n",
    "            })\n",
    "\n",
    "\n",
    "idio_vol_df = pd.DataFrame(idio_vol_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifie et supprime la colonne Idiovol si elle est déjà présente\n",
    "if \"Idiovol\" in merged_monthly_df.columns:\n",
    "    print(\"Colonne 'Idiovol' déjà présente — suppression avant merge.\")\n",
    "    merged_monthly_df = merged_monthly_df.drop(columns=[\"Idiovol\"])\n",
    "\n",
    "# Merge proprement\n",
    "merged_monthly_df = merged_monthly_df.merge(idio_vol_df, on=[\"Ticker\", \"Month\"], how=\"left\")\n",
    "\n",
    "# Vérifie le résultat\n",
    "print(merged_monthly_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check des datas : yearly (continuer le reste)\n",
    "covariate_cols = [\"agr\", \"cashpr\", \"chinv\", \"depr\", \"dy\", \"ep\", \"invest\", \"rd_mve\", \"sp\"]\n",
    "\n",
    "#mean of each covariates\n",
    "covariate_means = yearly_df[covariate_cols].mean()\n",
    "print(\"Moyennes des covariates :\")\n",
    "print(covariate_means)\n",
    "\n",
    "#standard-deviation of each covariate\n",
    "covariate_stds = yearly_df[covariate_cols].std()\n",
    "print(\"\\nÉcarts-types des covariates :\")\n",
    "print(covariate_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yearly_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly : cross-sectional ranking and normalization\n",
    "\n",
    "#first we need to standardize the date (because we exported the fiscal year, it's not the same for each stock)\n",
    "yearly_df[\"Year\"] = pd.to_datetime(yearly_df[\"Date\"]).dt.year\n",
    "\n",
    "# Filter to keep only years >= 1990\n",
    "yearly_df = yearly_df[yearly_df[\"Year\"] >= 1990]\n",
    "\n",
    "covariates = [\"agr\", \"cashpr\", \"chinv\", \"depr\", \"dy\", \"ep\", \"invest\", \"rd_mve\", \"sp\"]\n",
    "\n",
    "#Dictionnary to store the rankings\n",
    "rankings = {}\n",
    "\n",
    "for covariate in covariates:\n",
    "    print(f\"\\n=== RANKING PAR {covariate.upper()} ===\")\n",
    "    \n",
    "    for date, group in yearly_df.groupby(\"Year\"): \n",
    "        \n",
    "        #ranked by covariates (ascending)\n",
    "        ranked_group = group[[\"Ticker\", covariate]].sort_values(covariate).reset_index(drop=True)\n",
    "        \n",
    "        ranked_group[\"rank\"] = range(1, len(ranked_group) + 1) #ranked from 1 to n\n",
    "        n = len(ranked_group)\n",
    "        ranked_group[\"score\"] = ranked_group[\"rank\"].apply(  # →[-1, 1]\n",
    "            lambda r: 0 if n == 1 else 2*(r - 1)/(n - 1) - 1\n",
    "        )\n",
    "        \n",
    "        #the ranking is stored in a dictionary\n",
    "        if covariate not in rankings:\n",
    "            rankings[covariate] = {}\n",
    "        rankings[covariate][date] = ranked_group\n",
    "        \n",
    "        #print the first dates\n",
    "        if date in list(yearly_df[\"Year\"].unique())[:1]:  \n",
    "            print(f\"\\nDate {date}:\")\n",
    "            print(ranked_group.head())\n",
    "\n",
    "# Create yearly_covariates with original variables first\n",
    "cols = [\"Year\", \"Ticker\"] + covariates\n",
    "yearly_covariates = yearly_df[cols].dropna()   # optional .dropna() to keep complete cases\n",
    "\n",
    "# Add normalized scores to yearly_covariates\n",
    "for covariate in covariates:\n",
    "    normalized_scores = []\n",
    "    for _, row in yearly_covariates.iterrows():\n",
    "        year = row[\"Year\"]\n",
    "        ticker = row[\"Ticker\"]\n",
    "        if covariate in rankings and year in rankings[covariate]:\n",
    "            ticker_data = rankings[covariate][year][rankings[covariate][year][\"Ticker\"] == ticker]\n",
    "            if not ticker_data.empty:\n",
    "                normalized_scores.append(ticker_data[\"score\"].iloc[0])\n",
    "            else:\n",
    "                normalized_scores.append(np.nan)\n",
    "        else:\n",
    "            normalized_scores.append(np.nan)\n",
    "    \n",
    "    yearly_covariates[f\"{covariate}_normalized\"] = normalized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_monthly_df = merged_monthly_df[merged_monthly_df[\"Month\"] >= pd.Period(\"1990-12\", freq=\"M\")]\n",
    "\n",
    "\n",
    "nan_percent = merged_monthly_df.isna().mean() * 100\n",
    "print(nan_percent.sort_values(ascending=False).round(2))\n",
    "\n",
    "\n",
    "merged_monthly_df.to_excel(\"merged_monthly_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df.to_excel(\"beta_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly : cross-sectional ranking and normalizatio\n",
    "\n",
    "merged_monthly_df = merged_monthly_df[merged_monthly_df[\"Month\"] >= pd.Period(\"1990-01\", freq=\"M\")]\n",
    "\n",
    "covariates = [\"mom12m\", \"mom6m\", \"mom1m\", \"chmom\", \"maxret\", \"retvol\", \"baspread\", \"dolvol\", \"mvel1\", \"turn\", \"Beta\", \n",
    "\"Beta_squared\", \"Idiovol\"]\n",
    "\n",
    "monthly_rankings = {}\n",
    "\n",
    "for covariate in covariates:\n",
    "    print(f\"\\n=== RANKING PAR {covariate.upper()} ===\")\n",
    "    \n",
    "    for date, group in merged_monthly_df.groupby(\"Month\"):\n",
    "        \n",
    "        ranked_group = group[[\"Ticker\", covariate]].sort_values(covariate).reset_index(drop=True)\n",
    "        \n",
    "        ranked_group[\"rank\"] = range(1, len(ranked_group) + 1)\n",
    "        n = len(ranked_group)\n",
    "        ranked_group[\"score\"] = ranked_group[\"rank\"].apply(\n",
    "            lambda r: 0 if n == 1 else 2*(r - 1)/(n - 1) - 1\n",
    "        )\n",
    "        \n",
    "        if covariate not in monthly_rankings:\n",
    "            monthly_rankings[covariate] = {}\n",
    "        monthly_rankings[covariate][date] = ranked_group\n",
    "\n",
    "        if date in sorted(merged_monthly_df[\"Month\"].unique())[:1]:\n",
    "            print(f\"\\nDate {date}:\")\n",
    "            print(ranked_group.head())\n",
    "\n",
    "cols = [\"Month\", \"Ticker\"] + covariates\n",
    "monthly_covariates = merged_monthly_df[cols].dropna()\n",
    "\n",
    "for covariate in covariates:\n",
    "    normalized_scores = []\n",
    "    for _, row in monthly_covariates.iterrows():\n",
    "        month = row[\"Month\"]\n",
    "        ticker = row[\"Ticker\"]\n",
    "        if covariate in monthly_rankings and month in monthly_rankings[covariate]:\n",
    "            ticker_data = monthly_rankings[covariate][month][monthly_rankings[covariate][month][\"Ticker\"] == ticker]\n",
    "            if not ticker_data.empty:\n",
    "                normalized_scores.append(ticker_data[\"score\"].iloc[0])\n",
    "            else:\n",
    "                normalized_scores.append(np.nan)\n",
    "        else:\n",
    "            normalized_scores.append(np.nan)\n",
    "    \n",
    "    monthly_covariates[f\"{covariate}_normalized\"] = normalized_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
