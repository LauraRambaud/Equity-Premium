{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel files are read and a ticker column is added to each sheet\n",
    "\n",
    "repertoire = \"data/stocks\" \n",
    "dataframes_dict = {}\n",
    "\n",
    "for fichier in os.listdir(repertoire): \n",
    "    chemin_complet = os.path.join(repertoire, fichier)\n",
    "\n",
    "    if fichier.endswith((\".xls\", \".xlsx\")):  \n",
    "        print(f\"File found : {fichier}\")\n",
    "\n",
    "    try:\n",
    "        worksheet = pd.read_excel(chemin_complet, sheet_name=None)\n",
    "\n",
    "        for sheet_name, df in worksheet.items():\n",
    "            if 'Ticker' not in df.columns:\n",
    "                df['Ticker'] = sheet_name  \n",
    "                print(f\"Ticker added to {sheet_name}\")\n",
    "                dataframes_dict[f\"{fichier}_{sheet_name}\"] = df\n",
    "            else:\n",
    "                print(f\"Column 'Ticker' already existed in {fichier}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during the process {fichier} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables are renamed and split by frequency\n",
    "monthly_list = []\n",
    "yearly_list = []\n",
    "quarterly_list = []\n",
    "\n",
    "daily_data_list = [] #we create multiple lists because the start dates differ\n",
    "daily_tot_return_list = []\n",
    "daily_askbid_list = []\n",
    "\n",
    "gics_list = []\n",
    "\n",
    "for name, df in dataframes_dict.items():\n",
    "    rename_map = {\n",
    "        df.columns.values[0]: \"Date.1\",\n",
    "        df.columns.values[1]: \"Total_Assets\",\n",
    "        df.columns.values[2]: \"Common_Equity\",\n",
    "        df.columns.values[3]: \"Cash_And_Investments\",\n",
    "        df.columns.values[4]: \"R&D_Expenses\",\n",
    "        df.columns.values[5]: \"Inventories\",\n",
    "        df.columns.values[6]: \"Dividends_Paid\",\n",
    "        df.columns.values[7]: \"Gross_Fixed_Assets\",\n",
    "        df.columns.values[8]: \"Income_Before_Extra_Items\",\n",
    "        df.columns.values[9]: \"Sales_Revenue\",\n",
    "        df.columns.values[10]: \"Depreciation_Amortization\",\n",
    "\n",
    "        df.columns.values[12]: \"Date.2\",\n",
    "        df.columns.values[13]: \"Mkt_Cap_Yearly\",\n",
    "        df.columns.values[14]: \"Shares_Outstanding_Yearly\",\n",
    "        df.columns.values[15]: \"Long_Term_Debt\",\n",
    "\n",
    "        df.columns.values[17]: \"Date.3\",\n",
    "        df.columns.values[18]: \"Net_Income\",\n",
    "\n",
    "        df.columns.values[20]: \"Date.4\",\n",
    "        df.columns.values[21]: \"Shares_Outstanding_Monthly\",\n",
    "        df.columns.values[22]: \"Mkt_Cap_Monthly\",\n",
    "\n",
    "        df.columns.values[24]: \"Date.5\",\n",
    "        df.columns.values[25]: \"Px_Last\",\n",
    "        df.columns.values[26]: \"Shares_Outstanding_Daily\",\n",
    "        df.columns.values[27]: \"Volume\",\n",
    "\n",
    "        df.columns.values[29]: \"Date.6\",\n",
    "        df.columns.values[30]: \"Total_Return\",\n",
    "\n",
    "        df.columns.values[32]: \"Date.7\",\n",
    "        df.columns.values[33]: \"Px_Ask\",\n",
    "        df.columns.values[34]: \"Px_Bid\",\n",
    "\n",
    "        df.columns.values[42]: \"Industry\",\n",
    "        df.columns.values[43]: \"Sector\",\n",
    "\n",
    "    }\n",
    "\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    try:\n",
    "        df_yearly = df[[\n",
    "            \"Date.1\", \"Total_Assets\", \"Common_Equity\", \"Cash_And_Investments\",\n",
    "            \"R&D_Expenses\", \"Inventories\", \"Dividends_Paid\", \"Gross_Fixed_Assets\",\n",
    "            \"Income_Before_Extra_Items\", \"Sales_Revenue\", \"Depreciation_Amortization\",\n",
    "            \"Mkt_Cap_Yearly\", \"Shares_Outstanding_Yearly\", \"Long_Term_Debt\"\n",
    "        ]].copy()\n",
    "        \n",
    "        df_quarterly = df[[\"Date.3\", \"Net_Income\"]].copy()\n",
    "       \n",
    "        df_monthly = df[[\n",
    "            \"Date.4\", \"Shares_Outstanding_Monthly\", \"Mkt_Cap_Monthly\" \n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_data = df[[\n",
    "            \"Date.5\", \"Px_Last\", \"Shares_Outstanding_Daily\", \"Volume\"\n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_tot_return = df[[\n",
    "            \"Date.6\", \"Total_Return\"\n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_askbid= df[[\n",
    "            \"Date.7\", \"Px_Ask\", \"Px_Bid\"\n",
    "        ]].copy()\n",
    "\n",
    "        df_gics = df[[\n",
    "            \"Industry\", \"Sector\"\n",
    "        ]].copy()\n",
    "        \n",
    "        df_yearly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_quarterly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_monthly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_data['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_tot_return['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_askbid['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_gics['Ticker'] = df['Ticker'].iloc[0]\n",
    "\n",
    "        yearly_list.append(df_yearly)\n",
    "        quarterly_list.append(df_quarterly)\n",
    "        monthly_list.append(df_monthly)\n",
    "        daily_data_list.append(df_daily_data)\n",
    "        daily_tot_return_list.append(df_daily_tot_return)\n",
    "        daily_askbid_list.append(df_daily_askbid)\n",
    "        gics_list.append(df_gics)\n",
    "\n",
    "\n",
    "        print(f\"{name} : successful yearly / monthly / quarterly / gics split\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{name} : error during split : {e}\")\n",
    "\n",
    "yearly_df = pd.concat(yearly_list, ignore_index=True)\n",
    "quarterly_df = pd.concat(quarterly_list, ignore_index=True)\n",
    "monthly_df = pd.concat(monthly_list, ignore_index=True)\n",
    "\n",
    "daily_data_df = pd.concat(daily_data_list, ignore_index=True)\n",
    "daily_tot_return_df = pd.concat(daily_tot_return_list, ignore_index=True)\n",
    "daily_askbid_df = pd.concat(daily_askbid_list, ignore_index=True)\n",
    "\n",
    "gics_df = pd.concat(gics_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = {\n",
    "    \"yearly\": yearly_df,\n",
    "    \"quarterly\": quarterly_df,\n",
    "    \"monthly\": monthly_df,\n",
    "    \"daily_tot_return\": daily_tot_return_df,\n",
    "    \"daily_data\": daily_data_df,\n",
    "    \"daily_askbid\": daily_askbid_df,\n",
    "}\n",
    "\n",
    "for name, df in lists.items():\n",
    "    #we rename columns starting with \"Date.xxx\" to \"Date\"\n",
    "    df.rename(columns={col: \"Date\" for col in df.columns if col.startswith(\"Date\")}, inplace=True)\n",
    "    \n",
    "    #we convert \"Date\" column to datetime\n",
    "    if \"Date\" in df.columns:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "    \n",
    "    #we convert all other columns to float64 (excluding \"Date\" and \"Ticker\")\n",
    "    for col in df.columns:\n",
    "        if col not in [\"Date\", \"Ticker\"]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(\"float64\")\n",
    "\n",
    "    #display column information for verification\n",
    "    print(f\"--- {name.capitalize()} DataFrame ---\")\n",
    "    print(f\"  - Colonnes et Types:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"    - {col}: {df[col].dtype}\")\n",
    "    print(f\"  - Nombre de lignes: {df.shape[0]}\")\n",
    "    print(f\"  - Nombre de colonnes: {df.shape[1]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN Cells\n",
    "\"\"\"\n",
    "We remove rows where the date column is NaN. When splitting the data by frequency, each row is assigned a ticker.\n",
    "However, because daily data have more rows than other frequencies, the ticker is excessively duplicated in the lower-frequency \n",
    "DataFrames (monthly, quarterly, yearly), leading to rows that are mostly empty.\n",
    "Dropping rows without a date removes these redundancies without any loss of actual data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lists[\"yearly\"] = yearly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"quarterly\"] = quarterly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"monthly\"] = monthly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"daily_data\"] = daily_data_df.dropna(subset=[\"Date\"])\n",
    "lists[\"daily_tot_return\"] = daily_tot_return_df.dropna(subset=[\"Date\"])\n",
    "lists[\"daily_askbid\"] = daily_askbid_df.dropna(subset=[\"Date\"])\n",
    "\n",
    "all_nan_matrices = {}\n",
    "\n",
    "for name, df in lists.items():  \n",
    "    if \"Ticker\" in df.columns:\n",
    "        cols = [col for col in df.columns if col != \"Ticker\"]\n",
    "        nan_matrix = (\n",
    "            df.groupby(\"Ticker\")[cols]\n",
    "              .apply(lambda g: g.isna().mean() * 100)\n",
    "              .reset_index()\n",
    "        )\n",
    "        all_nan_matrices[name] = nan_matrix\n",
    "        print(f\"\\n % Pourcentage de NaN pour {name} :\\n\", nan_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN handling using SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#create an imputer to replace NaNs with the mean\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "for name, df in lists.items():\n",
    "    cols_to_impute = [col for col in df.columns if col not in [\"Date\", \"Ticker\"]]\n",
    "    df.loc[:, cols_to_impute] = df.groupby(\"Ticker\")[cols_to_impute].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df = lists[\"yearly\"]\n",
    "quarterly_df = lists[\"quarterly\"]\n",
    "monthly_df = lists[\"monthly\"]\n",
    "daily_data_df = lists[\"daily_data\"]\n",
    "daily_tot_return_df = lists[\"daily_tot_return\"]\n",
    "daily_askbid_df = lists[\"daily_askbid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly computations    \n",
    "\n",
    "#mkt cap and shares outstanding were extracted with a BDH formula and are expressed in millions so we have to multiply by 10^6\n",
    "cols_to_scale = [\"Mkt_Cap_Yearly\", \"Shares_Outstanding_Yearly\", \"Long_Term_Debt\"]\n",
    "yearly_df[cols_to_scale] = yearly_df[cols_to_scale] * 1e6\n",
    "\n",
    "daily_data_df[\"Shares_Outstanding_Daily\"] = daily_data_df[\"Shares_Outstanding_Daily\"] * 1e6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yearly_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly computations\n",
    "\n",
    "#asset growth (agr)\n",
    "yearly_df[\"agr\"] = (\n",
    "    yearly_df[\"Total_Assets\"] - yearly_df.groupby(\"Ticker\")[\"Total_Assets\"].shift(1)\n",
    ") / yearly_df.groupby(\"Ticker\")[\"Total_Assets\"].shift(1)\n",
    "\n",
    "\n",
    "#cash productivity (cashpr)\n",
    "yearly_df.loc[:, \"cashpr\"] = (\n",
    "    yearly_df[\"Mkt_Cap_Yearly\"] + yearly_df[\"Long_Term_Debt\"] - yearly_df[\"Total_Assets\"]\n",
    ") / yearly_df[\"Cash_And_Investments\"]\n",
    "\n",
    "\n",
    "#change in inventory (chinv)\n",
    "yearly_df[\"chinv\"] = (\n",
    "    yearly_df[\"Inventories\"] - yearly_df.groupby(\"Ticker\")[\"Inventories\"].shift(1)\n",
    ") / yearly_df[\"Total_Assets\"]\n",
    "\n",
    "#change in shares outstanding (chsh)   \n",
    "yearly_df[\"chsh\"] = (\n",
    "    yearly_df[\"Shares_Outstanding_Yearly\"] - yearly_df.groupby(\"Ticker\")[\"Shares_Outstanding_Yearly\"].shift(1)\n",
    ") / yearly_df.groupby(\"Ticker\")[\"Shares_Outstanding_Yearly\"].shift(1)\n",
    "\n",
    "#depreciation / Gross Fixed Assets (depr)\n",
    "yearly_df[\"depr\"] = (\n",
    "    yearly_df[\"Depreciation_Amortization\"] / \n",
    "    yearly_df[\"Gross_Fixed_Assets\"]\n",
    ")\n",
    "\n",
    "#dividends to Market Cap (dy)\n",
    "yearly_df[\"dy\"] = (\n",
    "    yearly_df[\"Dividends_Paid\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "#earnings to Price (ep)\n",
    "yearly_df[\"ep\"] = (\n",
    "    yearly_df[\"Income_Before_Extra_Items\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "#investment to assets (invest)\n",
    "yearly_df.loc[:, \"invest\"] = (\n",
    "    yearly_df.groupby(\"Ticker\")[\"Gross_Fixed_Assets\"].transform(lambda x: x - x.shift(1))\n",
    "    + yearly_df.groupby(\"Ticker\")[\"Inventories\"].transform(lambda x: x - x.shift(1))\n",
    ") / yearly_df.groupby(\"Ticker\")[\"Total_Assets\"].transform(lambda x: x.shift(1))\n",
    "\n",
    "\n",
    "#R&D to Market Value of Equity (rd_mve)\n",
    "yearly_df[\"rd_mve\"] = (\n",
    "    yearly_df[\"R&D_Expenses\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "#sales to Price (sp)\n",
    "yearly_df[\"sp\"] = (\n",
    "    yearly_df[\"Sales_Revenue\"] / \n",
    "    yearly_df[\"Mkt_Cap_Yearly\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quarterly computations\n",
    "\n",
    "quarterly_df[\"delta_income\"] = (\n",
    "    quarterly_df[\"Net_Income\"] - quarterly_df[\"Net_Income\"].shift(1)\n",
    ")\n",
    "\n",
    "quarterly_df[\"direction\"] = np.sign(quarterly_df[\"delta_income\"])\n",
    "\n",
    "def compute_nincr(direction_series):\n",
    "    nincr = []\n",
    "    count = 0\n",
    "    prev = 0\n",
    "    for d in direction_series:\n",
    "        if d == prev and d != 0:\n",
    "            count += 1\n",
    "        elif d != 0:\n",
    "            count = 1\n",
    "        else:\n",
    "            count = 0\n",
    "        nincr.append(count * d if d != 0 else 0)\n",
    "        prev = d if d != 0 else prev\n",
    "    return nincr\n",
    "\n",
    "quarterly_df[\"nincr\"] = (\n",
    "    quarterly_df.groupby(\"Ticker\")[\"direction\"].transform(compute_nincr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly computations\n",
    "\n",
    "tot_return_raw = daily_tot_return_df[[\"Date\", \"Ticker\", \"Total_Return\"]] #we'll need it to compute weekly returns for beta afterwards \n",
    "\n",
    "monthly_data = {\n",
    "    \"daily_tot_return_df\": daily_tot_return_df,\n",
    "    \"monthly_df\": monthly_df,\n",
    "    \"daily_data_df\": daily_data_df,\n",
    "    \"daily_askbid_df\": daily_askbid_df,\n",
    "}\n",
    "\n",
    "#date to monthly period\n",
    "for name, df in monthly_data.items():\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        df[\"Date\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "        print(f\"{name} : Date converted to monthly period\")\n",
    "    else:\n",
    "        print(f\"{name} : Date already converted\")\n",
    "\n",
    "#size (mvel1)\n",
    "monthly_df[\"mvel1\"] = (\n",
    "    monthly_df.groupby(\"Ticker\")[\"Mkt_Cap_Monthly\"]\n",
    "    .transform(lambda x: np.log(x).shift(1))\n",
    ")\n",
    "\n",
    "\n",
    "#dolvol computation\n",
    "dolvol_df = daily_data_df[[\"Date\", \"Ticker\", \"Volume\", \"Px_Last\"]]\n",
    "dolvol_df[\"dolvol\"] = dolvol_df[\"Volume\"] * dolvol_df[\"Px_Last\"]\n",
    "\n",
    "dolvol_df = (\n",
    "    dolvol_df.groupby([\"Ticker\", \"Date\"])[\"dolvol\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"dolvol_sum\")\n",
    ")\n",
    "\n",
    "dolvol_df[\"dolvol_monthly\"] = np.log(dolvol_df[\"dolvol_sum\"])\n",
    "dolvol_df[\"dolvol_lag2\"] = dolvol_df.groupby(\"Ticker\")[\"dolvol_monthly\"].shift(2)\n",
    "\n",
    "#bid-ask spread\n",
    "daily_askbid_df[\"mean bid-ask spread\"] = (\n",
    "    daily_askbid_df[\"Px_Ask\"]- daily_askbid_df[\"Px_Bid\"]\n",
    "    .groupby([daily_askbid_df[\"Ticker\"], daily_askbid_df[\"Date\"]])\n",
    "    .transform(\"mean\")\n",
    ") \n",
    "\n",
    "daily_askbid_df[\"mean daily spread\"] = (\n",
    "    daily_askbid_df[\"Px_Ask\"] + daily_askbid_df[\"Px_Bid\"]\n",
    ") / 2 \n",
    "\n",
    "daily_askbid_df[\"baspread\"] = (\n",
    "    daily_askbid_df[\"mean bid-ask spread\"] - daily_askbid_df[\"mean daily spread\"]\n",
    ")\n",
    "\n",
    "#momentums and maxret computations \n",
    "\n",
    "#daily return computation\n",
    "daily_tot_return_df[\"daily return\"] = (\n",
    "    (daily_tot_return_df[\"Total_Return\"] - daily_tot_return_df.groupby(\"Ticker\")[\"Total_Return\"].transform(\"shift\", 1))\n",
    "    / daily_tot_return_df.groupby(\"Ticker\")[\"Total_Return\"].transform(\"shift\", 1)\n",
    ")   \n",
    "\n",
    "#max return (maxret)\n",
    "maxret_df = (\n",
    "    daily_tot_return_df.groupby([\"Ticker\", \"Date\"])[\"daily return\"]\n",
    "    .max()\n",
    "    .groupby(level=0)\n",
    "    .shift(1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily return\": \"maxret\"})\n",
    ")\n",
    "\n",
    "#return volatility (retvol)\n",
    "retvol_df = (\n",
    "    daily_tot_return_df\n",
    "    .groupby([\"Ticker\", \"Date\"])[\"daily return\"]\n",
    "    .std()\n",
    "    .groupby(level=0)  \n",
    "    .shift(1)          \n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily return\": \"retvol\"})\n",
    ")\n",
    "\n",
    "#share turnover (turn)\n",
    "daily_data_df[\"Mean_Volume\"] = (\n",
    "    daily_data_df.groupby(\"Ticker\")[\"Volume\"].transform(\"mean\")\n",
    ")\n",
    "\n",
    "turn_df = (\n",
    "    daily_data_df.groupby([\"Ticker\", \"Date\"])[\"Mean_Volume\"].first().reset_index()\n",
    ")\n",
    "\n",
    "turn_df = turn_df.merge(\n",
    "    monthly_df[[\"Ticker\", \"Date\", \"Shares_Outstanding_Monthly\"]],\n",
    "    how=\"left\",\n",
    "    left_on=[\"Ticker\", \"Date\"],\n",
    "    right_on=[\"Ticker\", \"Date\"]\n",
    ")\n",
    "\n",
    "turn_df[\"turn\"] = (\n",
    "    turn_df[\"Mean_Volume\"]\n",
    "    .groupby(monthly_df[\"Ticker\"])\n",
    "    .transform(lambda x: x.rolling(window=3, min_periods=3).mean())\n",
    "    / turn_df[\"Shares_Outstanding_Monthly\"]\n",
    ")\n",
    "\n",
    "share_turnover_df = daily_data_df[[\"Ticker\", \"Date\", \"Volume\", \"Shares_Outstanding_Daily\"]].copy()\n",
    "\n",
    "share_turnover_df[\"daily_share_turnover\"] = (\n",
    "    share_turnover_df[\"Volume\"] / share_turnover_df[\"Shares_Outstanding_Daily\"]\n",
    ")\n",
    "\n",
    "stdturn_df = (\n",
    "    share_turnover_df.groupby([\"Ticker\", \"Date\"])[\"daily_share_turnover\"]\n",
    "    .std()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily_share_turnover\": \"stdturn\"})\n",
    ")\n",
    "\n",
    "#momentums computations\n",
    "#monthly compounded return computation\n",
    "monthly_return_df = (\n",
    "    daily_tot_return_df.groupby([\"Ticker\", \"Date\"])[\"daily return\"]\n",
    "    .apply(lambda x: (1 + x).prod() - 1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily return\": \"monthly return\"})\n",
    ")\n",
    "\n",
    "#36-month momentum (mom36m)\n",
    "monthly_return_df[\"mom36m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(13)).rolling(window=24, min_periods=24).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "#12-month mommentum (mom12m)\n",
    "monthly_return_df[\"mom12m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(2)).rolling(window=11, min_periods=11).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "#6-month momentum (mom6m)\n",
    "monthly_return_df[\"mom6m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(2)).rolling(window=5, min_periods=5).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "#1-month momentum (mom1m)\n",
    "monthly_return_df[\"mom1m\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"].shift(1)\n",
    ")\n",
    "\n",
    "#chmom \n",
    "monthly_return_df[\"chmom\"] = (\n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(1)).rolling(window=6, min_periods=6).apply(np.prod, raw=True) - 1) - \n",
    "    monthly_return_df.groupby(\"Ticker\")[\"monthly return\"]\n",
    "    .transform(lambda x: (1 + x.shift(7)).rolling(window=6, min_periods=6).apply(np.prod, raw=True) - 1)\n",
    "\n",
    ")\n",
    "\n",
    "#illiquidity \n",
    "ill_df = daily_data_df[[\"Date\", \"Ticker\", \"Volume\", \"Px_Last\"]].copy()\n",
    "\n",
    "ill_df[\"dolvol\"] = ill_df[\"Volume\"] * ill_df[\"Px_Last\"]\n",
    "\n",
    "ill_df[\"daily return\"] = (\n",
    "    ill_df.groupby(\"Ticker\")[\"Px_Last\"].transform(lambda x: x - x.shift(1)) /\n",
    "    ill_df.groupby(\"Ticker\")[\"Px_Last\"].transform(lambda x: x.shift(1))\n",
    ")\n",
    "\n",
    "ill_df[\"abs return\"] = ill_df[\"daily return\"].abs()\n",
    "\n",
    "ill_df[\"ill daily\"] = ill_df[\"abs return\"] / ill_df[\"dolvol\"]\n",
    "\n",
    "if not pd.api.types.is_period_dtype(ill_df[\"Date\"]):\n",
    "    ill_df[\"Date\"] = ill_df[\"Date\"].dt.to_period(\"M\")\n",
    "    print(\"Date column converted to monthly period\")\n",
    "else:\n",
    "    print(\"Date column is already a period object - no conversion needed\")\n",
    "\n",
    "illiquidity_monthly = (\n",
    "    ill_df.groupby([\"Ticker\", \"Date\"])[\"ill daily\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"ill daily\": \"illiq\"})\n",
    ")\n",
    "\n",
    "print(illiquidity_monthly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indmom\n",
    "gics_df = gics_df.drop_duplicates(subset=[\"Ticker\"])\n",
    "\n",
    "df_indmom = monthly_return_df[[\"Ticker\", \"Date\", \"monthly return\"]] \n",
    "df_indmom = df_indmom.merge(gics_df[['Ticker', 'Industry']], on='Ticker', how='left')\n",
    "df_indmom = df_indmom.sort_values(['Ticker', 'Date'])\n",
    "\n",
    "df_indmom['ret_12m'] = (\n",
    "    df_indmom.groupby('Ticker')['monthly return']\n",
    "    .transform(lambda x: (1 + x.shift(1)).rolling(window=12, min_periods=12).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "indret_df = (\n",
    "    df_indmom.dropna(subset=['ret_12m', 'Industry'])\n",
    "    .groupby(['Date', 'Industry'])['ret_12m']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'ret_12m': 'indret_12m'})\n",
    ")\n",
    "\n",
    "indmom_df = (\n",
    "    indret_df.groupby('Date')['indret_12m']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'indret_12m': 'indmom'})\n",
    ")\n",
    "\n",
    "df_indmom = df_indmom.merge(indmom_df, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tasks = [\n",
    "    {\"df\": dolvol_df, \"col\": \"dolvol_lag2\"},\n",
    "    {\"df\": maxret_df, \"col\": \"maxret\"},\n",
    "    {\"df\": retvol_df, \"col\": \"retvol\"},\n",
    "    {\"df\": monthly_return_df, \"col\": \"mom36m\"},\n",
    "    {\"df\": monthly_return_df, \"col\": \"mom12m\"},\n",
    "    {\"df\": monthly_return_df, \"col\": \"mom6m\"},\n",
    "    {\"df\": monthly_return_df, \"col\": \"mom1m\"},\n",
    "    {\"df\": monthly_return_df, \"col\": \"chmom\"},\n",
    "    {\"df\": turn_df, \"col\": \"turn\"},\n",
    "    {\"df\": df_indmom, \"col\": \"indmom\"},\n",
    "    {\"df\": illiquidity_monthly, \"col\": \"illiq\"},\n",
    "    {\"df\": stdturn_df, \"col\": \"stdturn\"},\n",
    "]\n",
    "\n",
    "\n",
    "for task in merge_tasks:\n",
    "    df_to_merge = task[\"df\"]\n",
    "    col = task[\"col\"]\n",
    "\n",
    "    if col not in monthly_df.columns:\n",
    "        print(f\"{col} merged into monthly_df\")\n",
    "        monthly_df = monthly_df.merge(\n",
    "            df_to_merge[[\"Ticker\", \"Date\", col]],\n",
    "            how=\"left\",\n",
    "            on=[\"Ticker\", \"Date\"]\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{col} already in monthly_df — skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly computations → beta\n",
    "\n",
    "#we need the weekly returns to compute beta\n",
    "tot_return_raw = tot_return_raw.set_index(\"Date\")\n",
    "weekly_prices = tot_return_raw.groupby(\"Ticker\")[\"Total_Return\"].resample(\"W\").last().reset_index()\n",
    "\n",
    "#weekly returns computation\n",
    "weekly_prices[\"weekly_return\"] = (\n",
    "    (weekly_prices[\"Total_Return\"] - weekly_prices.groupby(\"Ticker\")[\"Total_Return\"].transform(\"shift\", 1))\n",
    "    / weekly_prices.groupby(\"Ticker\")[\"Total_Return\"].transform(\"shift\", 1)\n",
    ")   \n",
    "\n",
    "pivot = weekly_prices.pivot(index=\"Date\", columns=\"Ticker\", values=\"weekly_return\") #transposée : 1 ligne par date \n",
    "pivot[\"Market\"] = pivot.mean(axis=1, skipna=True) #moyenne des returns par semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  #since the computation is long, we use tqdm to display a progress bar\n",
    "import statsmodels.api as sm\n",
    "\n",
    "results = []\n",
    "\n",
    "for ticker in tqdm(pivot.columns.drop(\"Market\")):\n",
    "    #we loop over each month, starting 3 years after the first date; freq=\"ME\" since we move month by month\n",
    "    for current_month in pd.date_range(start=pivot.index.min() + pd.DateOffset(years=3), \n",
    "                                       end=pivot.index.max(), freq=\"ME\"):\n",
    "\n",
    "        #current_month is already a timestamp\n",
    "        end_date = current_month - pd.DateOffset(months=1)\n",
    "        start_date = end_date - pd.DateOffset(years=3)\n",
    "\n",
    "        #extract weekly data for this 3-year window, containing the stock and market returns\n",
    "        try:\n",
    "            window = pivot.loc[start_date:end_date, [ticker, \"Market\"]].dropna()\n",
    "        except KeyError:\n",
    "            #fallback if the date does not exist exactly\n",
    "            window = pivot.loc[(pivot.index >= start_date) & (pivot.index <= end_date), [ticker, \"Market\"]].dropna()\n",
    "\n",
    "        #I thought I could remove the if, but apparently not?\n",
    "        if len(window) >= 156:  #156 weeks = 3 years\n",
    "            X = sm.add_constant(window[\"Market\"])  #explicative variable + constant (alpha)\n",
    "            y = window[ticker]  #dependent variable\n",
    "\n",
    "            model = sm.OLS(y, X).fit()  #linear regression with statsmodels\n",
    "            beta = model.params[\"Market\"]  #slope = beta\n",
    "            alpha = model.params[\"const\"]  #intercept = alpha\n",
    "            r_squared = model.rsquared  #model explanatory power\n",
    "            p_value = model.pvalues[\"Market\"] #pvalue of beta\n",
    "\n",
    "            results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Month\": current_month.to_period(\"M\"),\n",
    "                \"Beta\": beta,\n",
    "                \"Alpha\": alpha,\n",
    "                \"R2\": r_squared,\n",
    "                \"p_value\": p_value\n",
    "            })\n",
    "\n",
    "# final DataFrame\n",
    "beta_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#beta test : are the beta coherent \n",
    "# pvalue, beta, R², alpha → mean\n",
    "beta_cols = [\"Beta\", \"Alpha\", \"R2\", \"p_value\"]\n",
    "beta_means = beta_df[beta_cols].mean()\n",
    "beta_std = beta_df[beta_cols].std()\n",
    "\n",
    "print(\"Standard deviation is:\", beta_std)\n",
    "print(\"Means is:\", beta_means)\n",
    "\n",
    "#beta histogram\n",
    "beta_df[\"Beta\"].hist(bins=30); plt.title(\"Distribution des beta\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta squared\n",
    "beta_df[\"Beta_squared\"] = beta_df[\"Beta\"] ** 2\n",
    "\n",
    "#merge with merge_monthly_df\n",
    "beta_cols = beta_df[[\"Ticker\", \"Month\", \"Beta\", \"Beta_squared\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idiovol computation \n",
    "\n",
    "pivot[\"Market\"] = pivot.mean(axis=1, skipna=True)\n",
    "\n",
    "idio_vol_results = []\n",
    "\n",
    "for ticker in tqdm(pivot.columns.drop(\"Market\")):\n",
    "    for current_month in pd.date_range(start=pivot.index.min() + pd.DateOffset(years=3),\n",
    "                                       end=pivot.index.max(), freq=\"ME\"):\n",
    "\n",
    "        end_date = current_month\n",
    "        start_date = end_date - pd.DateOffset(years=3)\n",
    "\n",
    "        try:\n",
    "            window = pivot.loc[start_date:end_date, [ticker, \"Market\"]].dropna()\n",
    "        except KeyError:\n",
    "            window = pivot.loc[(pivot.index >= start_date) & \n",
    "                                      (pivot.index <= end_date), [ticker, \"Market\"]].dropna()\n",
    "\n",
    "        if len(window) >= 52:  # At least one year of data\n",
    "            X = sm.add_constant(window[\"Market\"])\n",
    "            y = window[ticker]\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            residuals = model.resid\n",
    "            idio_std = np.std(residuals)\n",
    "\n",
    "            idio_vol_results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Month\": current_month.to_period(\"M\"),\n",
    "                \"Idiovol\": idio_std\n",
    "            })\n",
    "\n",
    "\n",
    "idio_vol_df = pd.DataFrame(idio_vol_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge Beta and Beta_squared\n",
    "if \"Beta\" not in monthly_df.columns:\n",
    "    monthly_df = monthly_df.merge(\n",
    "        beta_df[[\"Ticker\", \"Month\", \"Beta\", \"Beta_squared\"]],\n",
    "        how=\"left\",\n",
    "        left_on=[\"Ticker\", \"Date\"],\n",
    "        right_on=[\"Ticker\", \"Month\"]\n",
    "    )\n",
    "    print(\"Beta and Beta_squared merged.\")\n",
    "else:\n",
    "    print(\"Beta already in monthly_df — skipping.\")\n",
    "\n",
    "# merge Idiovol\n",
    "if \"Idiovol\" not in monthly_df.columns:\n",
    "    monthly_df = monthly_df.merge(\n",
    "        idio_vol_df,\n",
    "        how=\"left\",\n",
    "        left_on=[\"Ticker\", \"Date\"],\n",
    "        right_on=[\"Ticker\", \"Month\"]\n",
    "    )\n",
    "    print(\"Idiovol merged.\")\n",
    "else:\n",
    "    print(\"Idiovol already in monthly_df — skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly : cross-sectional ranking and normalization\n",
    "\n",
    "#first we need to standardize the date (because we exported the fiscal year, it's not the same for each stock)\n",
    "yearly_df[\"Year\"] = pd.to_datetime(yearly_df[\"Date\"]).dt.year\n",
    "\n",
    "# Filter to keep only years >= 1990\n",
    "yearly_df = yearly_df[yearly_df[\"Year\"] >= 1990]\n",
    "\n",
    "covariates = [\"agr\", \"cashpr\", \"chinv\", \"depr\", \"dy\", \"ep\", \"invest\", \"rd_mve\", \"sp\"]\n",
    "\n",
    "#Dictionnary to store the rankings\n",
    "rankings = {}\n",
    "\n",
    "for covariate in covariates:\n",
    "    print(f\"\\n=== RANKING PAR {covariate.upper()} ===\")\n",
    "    \n",
    "    for date, group in yearly_df.groupby(\"Year\"): \n",
    "        \n",
    "        #ranked by covariates (ascending)\n",
    "        ranked_group = group[[\"Ticker\", covariate]].sort_values(covariate).reset_index(drop=True)\n",
    "        \n",
    "        ranked_group[\"rank\"] = range(1, len(ranked_group) + 1) #ranked from 1 to n\n",
    "        n = len(ranked_group)\n",
    "        ranked_group[\"score\"] = ranked_group[\"rank\"].apply(  # →[-1, 1]\n",
    "            lambda r: 0 if n == 1 else 2*(r - 1)/(n - 1) - 1\n",
    "        )\n",
    "        \n",
    "        #the ranking is stored in a dictionary\n",
    "        if covariate not in rankings:\n",
    "            rankings[covariate] = {}\n",
    "        rankings[covariate][date] = ranked_group\n",
    "        \n",
    "        #print the first dates\n",
    "        if date in list(yearly_df[\"Year\"].unique())[:1]:  \n",
    "            print(f\"\\nDate {date}:\")\n",
    "            print(ranked_group.head())\n",
    "\n",
    "# Create yearly_covariates with original variables first\n",
    "cols = [\"Year\", \"Ticker\"] + covariates\n",
    "yearly_covariates = yearly_df[cols].dropna()   # optional .dropna() to keep complete cases\n",
    "\n",
    "# Add normalized scores to yearly_covariates\n",
    "for covariate in covariates:\n",
    "    normalized_scores = []\n",
    "    for _, row in yearly_covariates.iterrows():\n",
    "        year = row[\"Year\"]\n",
    "        ticker = row[\"Ticker\"]\n",
    "        if covariate in rankings and year in rankings[covariate]:\n",
    "            ticker_data = rankings[covariate][year][rankings[covariate][year][\"Ticker\"] == ticker]\n",
    "            if not ticker_data.empty:\n",
    "                normalized_scores.append(ticker_data[\"score\"].iloc[0])\n",
    "            else:\n",
    "                normalized_scores.append(np.nan)\n",
    "        else:\n",
    "            normalized_scores.append(np.nan)\n",
    "    \n",
    "    yearly_covariates[f\"{covariate}_normalized\"] = normalized_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git-filter-repo\n",
      "  Downloading git_filter_repo-2.47.0-py3-none-any.whl.metadata (31 kB)\n",
      "Downloading git_filter_repo-2.47.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: git-filter-repo\n",
      "Successfully installed git-filter-repo-2.47.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script git-filter-repo.exe is installed in 'c:\\Users\\33676\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install git-filter-repo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
