{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel files are read and a ticker column is added to each sheet\n",
    "\n",
    "repertoire = \"data/raw/stocks\" \n",
    "dataframes_dict = {}\n",
    "\n",
    "for fichier in os.listdir(repertoire): \n",
    "    chemin_complet = os.path.join(repertoire, fichier)\n",
    "\n",
    "    if fichier.endswith((\".xls\", \".xlsx\")):  \n",
    "        print(f\"File found : {fichier}\")\n",
    "\n",
    "    try:\n",
    "        worksheet = pd.read_excel(chemin_complet, sheet_name=None)\n",
    "\n",
    "        for sheet_name, df in worksheet.items():\n",
    "            if 'Ticker' not in df.columns:\n",
    "                df['Ticker'] = sheet_name  \n",
    "                print(f\"Ticker added to {sheet_name}\")\n",
    "                dataframes_dict[f\"{fichier}_{sheet_name}\"] = df\n",
    "            else:\n",
    "                print(f\"Column 'Ticker' already existed in {fichier}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during the process {fichier} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables are renamed and split by frequency\n",
    "monthly_list = []\n",
    "yearly_list = []\n",
    "quarterly_list = []\n",
    "\n",
    "daily_data_list = [] #we create multiple lists because the start dates differ\n",
    "daily_tot_return_list = []\n",
    "daily_askbid_list = []\n",
    "\n",
    "gics_list = []\n",
    "\n",
    "for name, df in dataframes_dict.items():\n",
    "    rename_map = {\n",
    "        df.columns.values[0]: \"Date.1\",\n",
    "        df.columns.values[1]: \"Total_Assets\",\n",
    "        df.columns.values[2]: \"Common_Equity\",\n",
    "        df.columns.values[3]: \"Cash_And_Investments\",\n",
    "        df.columns.values[4]: \"R&D_Expenses\",\n",
    "        df.columns.values[5]: \"Inventories\",\n",
    "        df.columns.values[6]: \"Dividends_Paid\",\n",
    "        df.columns.values[7]: \"Gross_Fixed_Assets\",\n",
    "        df.columns.values[8]: \"Income_Before_Extra_Items\",\n",
    "        df.columns.values[9]: \"Sales_Revenue\",\n",
    "        df.columns.values[10]: \"Depreciation_Amortization\",\n",
    "\n",
    "        df.columns.values[12]: \"Date.2\",\n",
    "        df.columns.values[13]: \"Mkt_Cap_Yearly\",\n",
    "        df.columns.values[14]: \"Shares_Outstanding_Yearly\",\n",
    "        df.columns.values[15]: \"Long_Term_Debt\",\n",
    "\n",
    "        df.columns.values[17]: \"Date.3\",\n",
    "        df.columns.values[18]: \"Net_Income\",\n",
    "\n",
    "        df.columns.values[20]: \"Date.4\",\n",
    "        df.columns.values[21]: \"Shares_Outstanding_Monthly\",\n",
    "        df.columns.values[22]: \"Mkt_Cap_Monthly\",\n",
    "\n",
    "        df.columns.values[24]: \"Date.5\",\n",
    "        df.columns.values[25]: \"Px_Last\",\n",
    "        df.columns.values[26]: \"Shares_Outstanding_Daily\",\n",
    "        df.columns.values[27]: \"Volume\",\n",
    "\n",
    "        df.columns.values[29]: \"Date.6\",\n",
    "        df.columns.values[30]: \"Total_Return\",\n",
    "\n",
    "        df.columns.values[32]: \"Date.7\",\n",
    "        df.columns.values[33]: \"Px_Ask\",\n",
    "        df.columns.values[34]: \"Px_Bid\",\n",
    "\n",
    "        df.columns.values[42]: \"Industry\",\n",
    "        df.columns.values[43]: \"Sector\",\n",
    "\n",
    "    }\n",
    "\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    try:\n",
    "        df_yearly = df[[\n",
    "            \"Date.1\", \"Total_Assets\", \"Common_Equity\", \"Cash_And_Investments\",\n",
    "            \"R&D_Expenses\", \"Inventories\", \"Dividends_Paid\", \"Gross_Fixed_Assets\",\n",
    "            \"Income_Before_Extra_Items\", \"Sales_Revenue\", \"Depreciation_Amortization\",\n",
    "            \"Mkt_Cap_Yearly\", \"Shares_Outstanding_Yearly\", \"Long_Term_Debt\"\n",
    "        ]].copy()\n",
    "        \n",
    "        df_quarterly = df[[\"Date.3\", \"Net_Income\"]].copy()\n",
    "       \n",
    "        df_monthly = df[[\n",
    "            \"Date.4\", \"Shares_Outstanding_Monthly\", \"Mkt_Cap_Monthly\" \n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_data = df[[\n",
    "            \"Date.5\", \"Px_Last\", \"Shares_Outstanding_Daily\", \"Volume\"\n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_tot_return = df[[\n",
    "            \"Date.6\", \"Total_Return\"\n",
    "        ]].copy()\n",
    "\n",
    "        df_daily_askbid= df[[\n",
    "            \"Date.7\", \"Px_Ask\", \"Px_Bid\"\n",
    "        ]].copy()\n",
    "\n",
    "        df_gics = df[[\n",
    "            \"Industry\", \"Sector\"\n",
    "        ]].copy()\n",
    "        \n",
    "        df_yearly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_quarterly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_monthly['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_data['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_tot_return['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_daily_askbid['Ticker'] = df['Ticker'].iloc[0]\n",
    "        df_gics['Ticker'] = df['Ticker'].iloc[0]\n",
    "\n",
    "        yearly_list.append(df_yearly)\n",
    "        quarterly_list.append(df_quarterly)\n",
    "        monthly_list.append(df_monthly)\n",
    "        daily_data_list.append(df_daily_data)\n",
    "        daily_tot_return_list.append(df_daily_tot_return)\n",
    "        daily_askbid_list.append(df_daily_askbid)\n",
    "        gics_list.append(df_gics)\n",
    "\n",
    "\n",
    "        print(f\"{name} : successful yearly / monthly / quarterly / gics split\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{name} : error during split : {e}\")\n",
    "\n",
    "yearly_df = pd.concat(yearly_list, ignore_index=True)\n",
    "quarterly_df = pd.concat(quarterly_list, ignore_index=True)\n",
    "monthly_df = pd.concat(monthly_list, ignore_index=True)\n",
    "\n",
    "daily_data_df = pd.concat(daily_data_list, ignore_index=True)\n",
    "daily_tot_return_df = pd.concat(daily_tot_return_list, ignore_index=True)\n",
    "daily_askbid_df = pd.concat(daily_askbid_list, ignore_index=True)\n",
    "\n",
    "gics_df = pd.concat(gics_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = {\n",
    "    \"yearly\": yearly_df,\n",
    "    \"quarterly\": quarterly_df,\n",
    "    \"monthly\": monthly_df,\n",
    "    \"daily_tot_return\": daily_tot_return_df,\n",
    "    \"daily_data\": daily_data_df,\n",
    "    \"daily_askbid\": daily_askbid_df,\n",
    "}\n",
    "\n",
    "for name, df in lists.items():\n",
    "    #we rename columns starting with \"Date.xxx\" to \"Date\"\n",
    "    df.rename(columns={col: \"Date\" for col in df.columns if col.startswith(\"Date\")}, inplace=True)\n",
    "    \n",
    "    #we convert \"Date\" column to datetime\n",
    "    if \"Date\" in df.columns:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "    \n",
    "    #we convert all other columns to float64 (excluding \"Date\" and \"Ticker\")\n",
    "    for col in df.columns:\n",
    "        if col not in [\"Date\", \"Ticker\"]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(\"float64\")\n",
    "\n",
    "    #display column information for verification\n",
    "    print(f\"--- {name.capitalize()} DataFrame ---\")\n",
    "    print(f\"  - Colonnes et Types:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"    - {col}: {df[col].dtype}\")\n",
    "    print(f\"  - Nombre de lignes: {df.shape[0]}\")\n",
    "    print(f\"  - Nombre de colonnes: {df.shape[1]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN Cells\n",
    "\"\"\"\n",
    "We remove rows where the date column is NaN. When splitting the data by frequency, each row is assigned a ticker.\n",
    "However, because daily data have more rows than other frequencies, the ticker is excessively duplicated in the lower-frequency \n",
    "DataFrames (monthly, quarterly, yearly), leading to rows that are mostly empty.\n",
    "Dropping rows without a date removes these redundancies without any loss of actual data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lists[\"yearly\"] = yearly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"quarterly\"] = quarterly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"monthly\"] = monthly_df.dropna(subset=[\"Date\"])\n",
    "lists[\"daily_data\"] = daily_data_df.dropna(subset=[\"Date\"])\n",
    "lists[\"daily_tot_return\"] = daily_tot_return_df.dropna(subset=[\"Date\"])\n",
    "lists[\"daily_askbid\"] = daily_askbid_df.dropna(subset=[\"Date\"])\n",
    "\n",
    "all_nan_matrices = {}\n",
    "\n",
    "for name, df in lists.items():  \n",
    "    if \"Ticker\" in df.columns:\n",
    "        cols = [col for col in df.columns if col != \"Ticker\"]\n",
    "        nan_matrix = (\n",
    "            df.groupby(\"Ticker\")[cols]\n",
    "              .apply(lambda g: g.isna().mean() * 100)\n",
    "              .reset_index()\n",
    "        )\n",
    "        all_nan_matrices[name] = nan_matrix\n",
    "        print(f\"\\n % Pourcentage de NaN pour {name} :\\n\", nan_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaN handling using SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#create an imputer to replace NaNs with the mean\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "for name, df in lists.items():\n",
    "    cols_to_impute = [col for col in df.columns if col not in [\"Date\", \"Ticker\"]]\n",
    "    df.loc[:, cols_to_impute] = df.groupby(\"Ticker\")[cols_to_impute].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df = lists[\"yearly\"]\n",
    "quarterly_df = lists[\"quarterly\"]\n",
    "monthly_df = lists[\"monthly\"]\n",
    "daily_data_df = lists[\"daily_data\"]\n",
    "daily_tot_return_df = lists[\"daily_tot_return\"]\n",
    "daily_askbid_df = lists[\"daily_askbid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_monthly_period(df, date_column=\"Date\"):\n",
    "    \"\"\"Convertit la colonne Date en période mensuelle si nécessaire\"\"\"\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[date_column]):\n",
    "        df[date_column] = df[date_column].dt.to_period(\"M\")\n",
    "        print(f\"{date_column} converted to monthly period\")\n",
    "    else:\n",
    "        print(f\"{date_column} already in monthly period\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly computations    \n",
    "\n",
    "#mkt cap and shares outstanding were extracted with a BDH formula and are expressed in millions so we have to multiply by 10^6\n",
    "cols_to_scale = [\"Mkt_Cap_Yearly\", \"Shares_Outstanding_Yearly\", \"Long_Term_Debt\"]\n",
    "yearly_df[cols_to_scale] = yearly_df[cols_to_scale] * 1e6\n",
    "\n",
    "daily_data_df[\"Shares_Outstanding_Daily\"] = daily_data_df[\"Shares_Outstanding_Daily\"] * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. 1. Yearly and quarterly computations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. On mensualise les data yearly \n",
    "\n",
    "# --- 1.1 Création différents types de colonnes\n",
    "cols_stocks = [\"Total_Assets\", \"Common_Equity\", \"Cash_And_Investments\", \"Inventories\", \"Gross_Fixed_Assets\", \"Mkt_Cap_Yearly\", \n",
    "\"Shares_Outstanding_Yearly\", \"Long_Term_Debt\"]\n",
    "cols_flows = [\"R&D_Expenses\", \"Dividends_Paid\", \"Sales_Revenue\", \"Depreciation_Amortization\", \"Income_Before_Extra_Items\"]\n",
    "rows_monthly = []\n",
    "\n",
    "# --- 1.2 Calcul rendement que l'on mensualisera après \n",
    "yearly_df[\"dy\"] = yearly_df[\"Dividends_Paid\"] / yearly_df[\"Mkt_Cap_Yearly\"]\n",
    "\n",
    "# --- 1.3 Mensualisation des données : les stocks sont identiques sur 12 mois, les flux sont divisés par 12 et le rendement est mensualisé\n",
    "for index, row in yearly_df.iterrows():\n",
    "    year = row[\"Date\"].year\n",
    "    ticker = row[\"Ticker\"]\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        new_row = {\"Ticker\": ticker, \"Date\": pd.Period(year=year, month=month, freq=\"M\")}\n",
    "\n",
    "        for col in cols_stocks:\n",
    "            new_row[col] = row[col]\n",
    "\n",
    "        for col in cols_flows:\n",
    "            new_row[col] = row[col] / 12 if pd.notnull(row[col]) else None\n",
    "\n",
    "        dy_annual = row[\"dy\"]\n",
    "        new_row[\"dy\"] = (1 + dy_annual) ** (1/12) - 1 if pd.notnull(dy_annual) else None\n",
    "\n",
    "        rows_monthly.append(new_row)\n",
    "\n",
    "# 4. Résultat final\n",
    "monthly_from_yearly = pd.DataFrame(rows_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Computations\n",
    "\n",
    "# --- 2.1 Calculs basiques\n",
    "#asset growth (agr)\n",
    "monthly_from_yearly[\"agr\"] = (\n",
    "    monthly_from_yearly[\"Total_Assets\"] - monthly_from_yearly.groupby(\"Ticker\")[\"Total_Assets\"].shift(12)\n",
    ") / monthly_from_yearly.groupby(\"Ticker\")[\"Total_Assets\"].shift(12)\n",
    "\n",
    "\n",
    "#cash productivity (cashpr)\n",
    "monthly_from_yearly[\"cashpr\"] = (\n",
    "    monthly_from_yearly[\"Mkt_Cap_Yearly\"] + monthly_from_yearly[\"Long_Term_Debt\"] - monthly_from_yearly[\"Total_Assets\"]\n",
    ") / monthly_from_yearly[\"Cash_And_Investments\"]\n",
    "\n",
    "\n",
    "#change in inventory (chinv)\n",
    "monthly_from_yearly[\"chinv\"] = (\n",
    "    monthly_from_yearly[\"Inventories\"] - monthly_from_yearly.groupby(\"Ticker\")[\"Inventories\"].shift(12)\n",
    ") / monthly_from_yearly[\"Total_Assets\"]\n",
    "\n",
    "#change in shares outstanding (chsh)   \n",
    "monthly_from_yearly[\"chsh\"] = (\n",
    "    monthly_from_yearly[\"Shares_Outstanding_Yearly\"] - monthly_from_yearly.groupby(\"Ticker\")[\"Shares_Outstanding_Yearly\"].shift(12)\n",
    ") / monthly_from_yearly.groupby(\"Ticker\")[\"Shares_Outstanding_Yearly\"].shift(12)\n",
    "\n",
    "#depreciation / Gross Fixed Assets (depr)\n",
    "monthly_from_yearly[\"depr\"] = (\n",
    "    monthly_from_yearly[\"Depreciation_Amortization\"] /\n",
    "    monthly_from_yearly[\"Gross_Fixed_Assets\"]\n",
    ")\n",
    "\n",
    "#earnings to Price (ep)\n",
    "monthly_from_yearly[\"ep\"] = (\n",
    "    monthly_from_yearly[\"Income_Before_Extra_Items\"] /\n",
    "    monthly_from_yearly[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "#investment to assets (invest)\n",
    "monthly_from_yearly[\"invest\"] = (\n",
    "    monthly_from_yearly.groupby(\"Ticker\")[\"Gross_Fixed_Assets\"].transform(lambda x: x - x.shift(12)) +\n",
    "    monthly_from_yearly.groupby(\"Ticker\")[\"Inventories\"].transform(lambda x: x - x.shift(12))\n",
    ") / monthly_from_yearly.groupby(\"Ticker\")[\"Total_Assets\"].transform(lambda x: x.shift(12))\n",
    "\n",
    "\n",
    "#R&D to Market Value of Equity (rd_mve)\n",
    "monthly_from_yearly[\"rd_mve\"] = (\n",
    "    monthly_from_yearly[\"R&D_Expenses\"] /\n",
    "    monthly_from_yearly[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "\n",
    "#sales to Price (sp)\n",
    "monthly_from_yearly[\"sp\"] = (\n",
    "    monthly_from_yearly[\"Sales_Revenue\"] /\n",
    "    monthly_from_yearly[\"Mkt_Cap_Yearly\"]\n",
    ")\n",
    "\n",
    "# --- 2.2 On filtre les données on ne garde les covariates à partir de 1990-12\n",
    "yearly_cov = monthly_from_yearly[[\"Ticker\", \"Date\", \"agr\", \"cashpr\", \"chinv\", \"chsh\", \"depr\", \"dy\", \"ep\", \"invest\", \"rd_mve\", \"sp\"]].copy()\n",
    "yearly_cov = yearly_cov[yearly_cov[\"Date\"] >= pd.Period(\"1990-12\", freq=\"M\")]\n",
    "yearly_cov = yearly_cov.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quarterly computations\n",
    "quarterly_df[\"delta_income\"] = (\n",
    "    quarterly_df[\"Net_Income\"] - quarterly_df[\"Net_Income\"].shift(1)\n",
    ")\n",
    "\n",
    "quarterly_df[\"direction\"] = np.sign(quarterly_df[\"delta_income\"])\n",
    "\n",
    "def compute_nincr(direction_series):\n",
    "    nincr = []\n",
    "    count = 0\n",
    "    prev = 0\n",
    "    for d in direction_series:\n",
    "        if d == prev and d != 0:\n",
    "            count += 1\n",
    "        elif d != 0:\n",
    "            count = 1\n",
    "        else:\n",
    "            count = 0\n",
    "        capped_count = min(count, 8)\n",
    "        nincr.append(count * d if d != 0 else 0)\n",
    "        prev = d if d != 0 else prev\n",
    "    return nincr\n",
    "\n",
    "quarterly_df[\"nincr\"] = (\n",
    "    quarterly_df.groupby(\"Ticker\")[\"direction\"].transform(compute_nincr)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II.2. Monthly computations \n",
    "\n",
    "Each subsections correspond to a variable family : momentums, illiquidity, risks, size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_return_raw = daily_tot_return_df[[\"Date\", \"Ticker\", \"Total_Return\"]].copy() #we'll need it to compute weekly returns for beta afterwards \n",
    "\n",
    "monthly_data = {\n",
    "    \"daily_tot_return_df\": daily_tot_return_df,\n",
    "    \"monthly_df\": monthly_df,\n",
    "    \"daily_data_df\": daily_data_df,\n",
    "    \"daily_askbid_df\": daily_askbid_df,\n",
    "}\n",
    "\n",
    "#date to monthly period\n",
    "for name, df in monthly_data.items():\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[\"Date\"]):\n",
    "        df[\"Date\"] = df[\"Date\"].dt.to_period(\"M\")\n",
    "        print(f\"{name} : Date converted to monthly period\")\n",
    "    else:\n",
    "        print(f\"{name} : Date already converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Momentum Variables\n",
    "\n",
    "#daily return computation\n",
    "df_daily_return = daily_tot_return_df[[\"Date\", \"Ticker\", \"Total_Return\"]].copy()\n",
    "\n",
    "df_daily_return[\"daily_return\"] = (\n",
    "    df_daily_return.groupby(\"Ticker\")[\"Total_Return\"].pct_change()\n",
    ")\n",
    "\n",
    "df_daily_return = convert_to_monthly_period(df_daily_return)\n",
    "\n",
    "# --- 1.1 Momentum computation\n",
    "def compute_momentum(df, lag_start, lag_end):\n",
    "    return (1 + df.shift(lag_start)).rolling(lag_end - lag_start + 1, min_periods=lag_end - lag_start + 1).apply(np.prod, raw=True) - 1\n",
    "\n",
    "df_monthly_return = (\n",
    "    df_daily_return.groupby([\"Ticker\", \"Date\"])[\"daily_return\"]\n",
    "    .apply(lambda x: (1 + x).prod() - 1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily_return\": \"monthly_return\"})\n",
    ")\n",
    "\n",
    "df_momentum = df_monthly_return.copy()\n",
    "df_momentum[\"mom1m\"] = df_momentum.groupby(\"Ticker\")[\"monthly_return\"].shift(1)\n",
    "df_momentum[\"mom6m\"] = df_momentum.groupby(\"Ticker\")[\"monthly_return\"].transform(lambda x: compute_momentum(x, 2, 6))\n",
    "df_momentum[\"mom12m\"] = df_momentum.groupby(\"Ticker\")[\"monthly_return\"].transform(lambda x: compute_momentum(x, 2, 12))\n",
    "df_momentum[\"mom36m\"] = df_momentum.groupby(\"Ticker\")[\"monthly_return\"].transform(lambda x: compute_momentum(x, 14, 37))\n",
    "df_momentum[\"chmom\"] = (\n",
    "    df_momentum.groupby(\"Ticker\")[\"monthly_return\"].transform(lambda x: compute_momentum(x, 1, 6)) -\n",
    "    df_momentum.groupby(\"Ticker\")[\"monthly_return\"].transform(lambda x: compute_momentum(x, 7, 12))\n",
    ")\n",
    "\n",
    "# --- 1.2 Maximum Return (maxret)\n",
    "maxret_df = (\n",
    "    df_daily_return.groupby([\"Ticker\", \"Date\"])[\"daily_return\"]\n",
    "    .max()\n",
    "    .groupby(level=0)\n",
    "    .shift(1)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily_return\": \"maxret\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Liquidity Variables\n",
    "\n",
    "# --- 2.1 Dollar Volume (dolvol_lag2)\n",
    "\n",
    "df_dolvol = daily_data_df[[\"Date\", \"Ticker\", \"Volume\", \"Px_Last\"]].copy()\n",
    "df_dolvol[\"dolvol\"] = df_dolvol[\"Volume\"] * df_dolvol[\"Px_Last\"]\n",
    "df_dolvol = convert_to_monthly_period(df_dolvol)\n",
    "\n",
    "df_dolvol = (\n",
    "    df_dolvol.groupby([\"Ticker\", \"Date\"])[\"dolvol\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"dolvol_sum\")\n",
    ")\n",
    "\n",
    "df_dolvol[\"dolvol_monthly\"] = np.log(df_dolvol[\"dolvol_sum\"])\n",
    "df_dolvol[\"dolvol_lag2\"] = df_dolvol.groupby(\"Ticker\")[\"dolvol_monthly\"].shift(2)\n",
    "\n",
    "\n",
    "# --- 2.2 Bid-Ask Spread (mean_baspread)\n",
    "\n",
    "df_baspread = daily_askbid_df[[\"Date\", \"Ticker\", \"Px_Ask\", \"Px_Bid\"]].copy()\n",
    "df_baspread[\"baspread\"] = (\n",
    "    (df_baspread[\"Px_Ask\"] - df_baspread[\"Px_Bid\"]) /\n",
    "    ((df_baspread[\"Px_Ask\"] + df_baspread[\"Px_Bid\"]) / 2)\n",
    ")\n",
    "df_baspread = convert_to_monthly_period(df_baspread)\n",
    "\n",
    "df_baspread = (\n",
    "    df_baspread\n",
    "    .groupby([\"Ticker\", \"Date\"], as_index=False)[\"baspread\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# --- 2.3 Illiquidity (illiq)\n",
    "\n",
    "df_ill = daily_data_df[[\"Date\", \"Ticker\", \"Volume\", \"Px_Last\"]].copy()\n",
    "df_ill[\"daily_return\"] = df_ill.groupby(\"Ticker\")[\"Px_Last\"].pct_change()\n",
    "df_ill[\"abs_return\"] = df_ill[\"daily_return\"].abs()\n",
    "df_ill[\"dolvol\"] = df_ill[\"Volume\"] * df_ill[\"Px_Last\"]\n",
    "df_ill[\"ill_daily\"] = df_ill[\"abs_return\"] / df_ill[\"dolvol\"]\n",
    "df_ill= convert_to_monthly_period(df_ill)\n",
    "\n",
    "df_illiq = (\n",
    "    df_ill.groupby([\"Ticker\", \"Date\"])[\"ill_daily\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"ill_daily\": \"illiq\"})\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2.4 Share Turnover (turn)\n",
    "\n",
    "df_turn = daily_data_df[[\"Date\", \"Ticker\", \"Volume\"]].copy()\n",
    "df_turn = convert_to_monthly_period(df_turn)\n",
    "\n",
    "# Moyenne quotidienne du volume par mois\n",
    "df_turn[\"mean_volume\"] = df_turn.groupby([\"Ticker\", \"Date\"])[\"Volume\"].transform(\"mean\")\n",
    "df_turn = df_turn.drop_duplicates(subset=[\"Ticker\", \"Date\"])[[\"Ticker\", \"Date\", \"mean_volume\"]]\n",
    "\n",
    "df_turn = df_turn.merge(\n",
    "    monthly_df[[\"Ticker\", \"Date\", \"Shares_Outstanding_Monthly\"]],\n",
    "    on=[\"Ticker\", \"Date\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_turn[\"turn\"] = (\n",
    "    df_turn.groupby(\"Ticker\")[\"mean_volume\"]\n",
    "    .transform(lambda x: x.rolling(3, min_periods=3).mean())\n",
    "    / df_turn[\"Shares_Outstanding_Monthly\"]\n",
    ")\n",
    "\n",
    "# --- 2.5 Share Turnover Volatility (stdturn)\n",
    "\n",
    "df_stdturn = daily_data_df[[\"Date\", \"Ticker\", \"Volume\", \"Shares_Outstanding_Daily\"]].copy()\n",
    "df_stdturn = convert_to_monthly_period(df_stdturn)\n",
    "df_stdturn[\"daily_turn\"] = df_stdturn[\"Volume\"] / df_stdturn[\"Shares_Outstanding_Daily\"]\n",
    "\n",
    "df_stdturn = (\n",
    "    df_stdturn.groupby([\"Ticker\", \"Date\"])[\"daily_turn\"]\n",
    "    .std()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily_turn\": \"stdturn\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Size and Valuation Variables\n",
    "\n",
    "df_size = monthly_df[[\"Ticker\", \"Date\", \"Mkt_Cap_Monthly\"]].copy()\n",
    "df_size[\"mvel1\"] = (\n",
    "    df_size.groupby(\"Ticker\")[\"Mkt_Cap_Monthly\"]\n",
    "    .transform(lambda x: np.log(x).shift(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Industry Variables\n",
    "\n",
    "# --- 4.1 Merge industry info\n",
    "df_industry = gics_df.drop_duplicates(subset=[\"Ticker\"])[[\"Ticker\", \"Sector\"]]\n",
    "\n",
    "df_indmom = df_monthly_return[[\"Ticker\", \"Date\", \"monthly_return\"]].copy()\n",
    "df_indmom = df_indmom.merge(df_industry, on=\"Ticker\", how=\"left\")\n",
    " \n",
    " # --- 4.2 Compute 12-month momentum per firm\n",
    "df_indmom[\"ret_12m\"] = (\n",
    "    df_indmom.groupby(\"Ticker\")[\"monthly_return\"]\n",
    "    .transform(lambda x: (1 + x.shift(1)).rolling(12, min_periods=12).apply(np.prod, raw=True) - 1)\n",
    ")\n",
    "\n",
    "# --- 4.3 Average return per Industry × Date\n",
    "df_indret = (\n",
    "    df_indmom.groupby([\"Date\", \"Sector\"])[\"ret_12m\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"ret_12m\": \"indmom\"})\n",
    ")\n",
    "\n",
    "df_indmom = df_indmom.merge(df_indret, on=[\"Date\", \"Sector\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Excess Return Computation\n",
    "\n",
    "df_rf_raw = pd.read_excel(\"data/raw/rf rate/rf Fama&French.xlsx\")\n",
    "\n",
    "# Use only date + risk-free column (assumed to be column 5)\n",
    "df_rf = df_rf_raw.iloc[:, [0, 4]].copy()\n",
    "df_rf.columns = [\"Date\", \"rf\"]\n",
    "\n",
    "# Clean numeric format (remove commas, convert to float)\n",
    "df_rf[\"rf\"] = (\n",
    "    df_rf[\"rf\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \"\")\n",
    "    .where(lambda x: x.str.match(r\"^-?\\d+(\\.\\d+)?$\", na=False))\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df_rf[\"rf\"] = df_rf[\"rf\"] / 100\n",
    "\n",
    "# Convert date to Period(M)\n",
    "df_rf[\"Date\"] = pd.to_datetime(df_rf[\"Date\"], format=\"%Y%m\", errors=\"coerce\").dt.to_period(\"M\")\n",
    "df_rf = df_rf.dropna(subset=[\"Date\", \"rf\"])\n",
    "\n",
    "# --- 5.2 Merge with monthly returns\n",
    "\n",
    "df_excess = df_monthly_return.merge(df_rf, on=\"Date\", how=\"left\")\n",
    "df_excess[\"excess_return\"] = df_excess[\"monthly_return\"] - df_excess[\"rf\"]\n",
    "\n",
    "# Final clean DataFrame\n",
    "df_excess_return = df_excess[[\"Date\", \"Ticker\", \"excess_return\"]]\n",
    "\n",
    "df_excess_return = df_excess_return[df_excess_return[\"Date\"] >= pd.Period(\"1990-12\", freq=\"M\")]\n",
    "df_excess_return.sort_values([\"Ticker\", \"Date\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Risk and Volatility Variables\n",
    "\n",
    "#return volatility (retvol)\n",
    "retvol_df = (\n",
    "    df_daily_return\n",
    "    .groupby([\"Ticker\", \"Date\"])[\"daily_return\"]\n",
    "    .std()\n",
    "    .groupby(level=0)  \n",
    "    .shift(1)          \n",
    "    .reset_index()\n",
    "    .rename(columns={\"daily_return\": \"retvol\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Beta Computation\n",
    "\n",
    "# --- 7.1 Weekly returns computation\n",
    "tot_return_raw = tot_return_raw.set_index(\"Date\")\n",
    "weekly_prices = tot_return_raw.groupby(\"Ticker\")[\"Total_Return\"].resample(\"W\").last().reset_index()\n",
    "\n",
    "weekly_prices[\"weekly_return\"] = (\n",
    "    (weekly_prices[\"Total_Return\"] - weekly_prices.groupby(\"Ticker\")[\"Total_Return\"].transform(\"shift\", 1))\n",
    "    / weekly_prices.groupby(\"Ticker\")[\"Total_Return\"].transform(\"shift\", 1)\n",
    ")   \n",
    "\n",
    "pivot = weekly_prices.pivot(index=\"Date\", columns=\"Ticker\", values=\"weekly_return\") #transposée : 1 ligne par date \n",
    "pivot[\"Market\"] = pivot.mean(axis=1, skipna=True) #moyenne des returns par semaine\n",
    "\n",
    "# --- 7.2 Linear Regression\n",
    "\n",
    "from tqdm import tqdm  #since the computation is long, we use tqdm to display a progress bar\n",
    "import statsmodels.api as sm\n",
    "\n",
    "results = []\n",
    "\n",
    "for ticker in tqdm(pivot.columns.drop(\"Market\")):\n",
    "    #we loop over each month, starting 3 years after the first date; freq=\"ME\" since we move month by month\n",
    "    for current_month in pd.date_range(start=pivot.index.min() + pd.DateOffset(years=3), \n",
    "                                       end=pivot.index.max(), freq=\"ME\"):\n",
    "\n",
    "        #current_month is already a timestamp\n",
    "        end_date = current_month - pd.DateOffset(months=1)\n",
    "        start_date = end_date - pd.DateOffset(years=3)\n",
    "\n",
    "        #extract weekly data for this 3-year window, containing the stock and market returns\n",
    "        try:\n",
    "            window = pivot.loc[start_date:end_date, [ticker, \"Market\"]].dropna()\n",
    "        except KeyError:\n",
    "            #fallback if the date does not exist exactly\n",
    "            window = pivot.loc[(pivot.index >= start_date) & (pivot.index <= end_date), [ticker, \"Market\"]].dropna()\n",
    "\n",
    "        if len(window) >= 156:  #156 weeks = 3 years\n",
    "            X = sm.add_constant(window[\"Market\"])  #explicative variable + constant (alpha)\n",
    "            y = window[ticker]  #dependent variable\n",
    "\n",
    "            model = sm.OLS(y, X).fit()  #linear regression with statsmodels\n",
    "            beta = model.params[\"Market\"]  #slope = beta\n",
    "            alpha = model.params[\"const\"]  #intercept = alpha\n",
    "            r_squared = model.rsquared  \n",
    "            p_value = model.pvalues[\"Market\"] #pvalue of beta\n",
    "\n",
    "            results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Date\": current_month.to_period(\"M\"),\n",
    "                \"beta\": beta,\n",
    "                \"Alpha\": alpha,\n",
    "                \"R2\": r_squared,\n",
    "                \"p_value\": p_value\n",
    "            })\n",
    "\n",
    "# final DataFrame + B²\n",
    "beta_df = pd.DataFrame(results)\n",
    "beta_df[\"beta_squared\"] = beta_df[\"beta\"]**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Idiovol Computation\n",
    "\n",
    "pivot[\"Market\"] = pivot.mean(axis=1, skipna=True)\n",
    "\n",
    "idio_vol_results = []\n",
    "\n",
    "for ticker in tqdm(pivot.columns.drop(\"Market\")):\n",
    "    for current_month in pd.date_range(start=pivot.index.min() + pd.DateOffset(years=3),\n",
    "                                       end=pivot.index.max(), freq=\"ME\"):\n",
    "\n",
    "        end_date = current_month\n",
    "        start_date = end_date - pd.DateOffset(years=3)\n",
    "\n",
    "        try:\n",
    "            window = pivot.loc[start_date:end_date, [ticker, \"Market\"]].dropna()\n",
    "        except KeyError:\n",
    "            window = pivot.loc[(pivot.index >= start_date) & \n",
    "                                      (pivot.index <= end_date), [ticker, \"Market\"]].dropna()\n",
    "\n",
    "        if len(window) >= 52:  # At least one year of data\n",
    "            X = sm.add_constant(window[\"Market\"])\n",
    "            y = window[ticker]\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            residuals = model.resid\n",
    "            idio_std = np.std(residuals)\n",
    "\n",
    "            idio_vol_results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Date\": current_month.to_period(\"M\"),\n",
    "                \"idiovol\": idio_std\n",
    "            })\n",
    "\n",
    "idio_vol_df = pd.DataFrame(idio_vol_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Standarisation and mensualisation des variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quarterly_df = convert_to_monthly_period(quarterly_df)\n",
    "\n",
    "# Étape 2 : création d'une timeline mensuelle complète\n",
    "timeline = pd.period_range(start=\"1990-01\", end=\"2020-12\", freq=\"M\") #génère tout les mois de la période\n",
    "monthly_rows = []\n",
    "\n",
    "# Étape 3 : itération sur les dates trimestrielles\n",
    "for i in range(len(quarterly_df)): #on lit une ligne une à une\n",
    "    base_period = quarterly_df.iloc[i][\"Date\"] #on récupère la date trimestrielle\n",
    "    value = quarterly_df.iloc[i][\"nincr\"] #on récupère la valeur de nincr\n",
    "    ticker = quarterly_df.iloc[i][\"Ticker\"] #on récupère le ticker\n",
    "\n",
    "    # Propager sur 3 mois : base, base+1, base+2\n",
    "    for offset in range(3): #on propage sur 3 mois  \n",
    "        target_period = base_period + offset #on ajoute l'offset à la date trimestrielle\n",
    "        if target_period in timeline: #on vérifie si la date est dans la timeline\n",
    "            monthly_rows.append({ #on ajoute la ligne au DataFrame\n",
    "                \"Ticker\": ticker,\n",
    "                \"Date\": target_period,  # date de fin de mois\n",
    "                \"nincr\": value #on ajoute la valeur de nincr\n",
    "            })\n",
    "\n",
    "#df final mensualisé \n",
    "monthly_nincr_df = pd.DataFrame(monthly_rows)\n",
    "monthly_nincr_df = monthly_nincr_df[monthly_nincr_df[\"Date\"] >= pd.Period(\"1990-12\", freq=\"M\")]\n",
    "monthly_nincr_df.sort_values([\"Ticker\", \"Date\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Merging the monthly dataframes\n",
    "monthly_covariates = monthly_df[[\"Ticker\", \"Date\"]].copy()\n",
    "monthly_covariates = monthly_covariates[monthly_covariates[\"Date\"] >= pd.Period(\"1990-12\", freq=\"M\")]\n",
    "\n",
    "def prepare_df(df):\n",
    "    df[\"Date\"] = df[\"Date\"].astype(\"period[M]\")\n",
    "    df = df[df[\"Date\"] >= pd.Period(\"1990-12\", freq=\"M\")].copy()\n",
    "    return df.reset_index(drop=True)\n",
    "df_dolvol = prepare_df(df_dolvol)\n",
    "maxret_df = prepare_df(maxret_df)\n",
    "retvol_df = prepare_df(retvol_df)\n",
    "df_momentum = prepare_df(df_momentum)\n",
    "df_turn = prepare_df(df_turn)\n",
    "df_indmom = prepare_df(df_indmom)\n",
    "df_baspread = prepare_df(df_baspread)\n",
    "df_illiq = prepare_df(df_illiq)\n",
    "df_stdturn = prepare_df(df_stdturn)\n",
    "beta_df = prepare_df(beta_df)\n",
    "idio_vol_df = prepare_df(idio_vol_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tasks = [\n",
    "    {\"df\": df_dolvol, \"col\": \"dolvol_lag2\"},\n",
    "    {\"df\": maxret_df, \"col\": \"maxret\"},\n",
    "    {\"df\": retvol_df, \"col\": \"retvol\"},\n",
    "    {\"df\": df_momentum, \"col\": \"mom36m\"},\n",
    "    {\"df\": df_momentum, \"col\": \"mom12m\"},\n",
    "    {\"df\": df_momentum, \"col\": \"mom6m\"},\n",
    "    {\"df\": df_momentum, \"col\": \"mom1m\"},\n",
    "    {\"df\": df_momentum, \"col\": \"chmom\"},\n",
    "    {\"df\": df_turn, \"col\": \"turn\"},\n",
    "    {\"df\": df_indmom, \"col\": \"indmom\"},\n",
    "    {\"df\": df_baspread, \"col\": \"baspread\"},\n",
    "    {\"df\": df_illiq, \"col\": \"illiq\"},\n",
    "    {\"df\": df_stdturn, \"col\": \"stdturn\"},\n",
    "    {\"df\": beta_df, \"col\": \"beta\"},\n",
    "    {\"df\": beta_df, \"col\": \"beta_squared\"},\n",
    "    {\"df\": idio_vol_df, \"col\": \"idiovol\"},\n",
    "    {\"df\": df_size, \"col\": \"mvel1\"},\n",
    "]\n",
    "\n",
    "for task in merge_tasks:\n",
    "    df_to_merge = task[\"df\"]\n",
    "    col = task[\"col\"]\n",
    "\n",
    "    df_to_merge = df_to_merge[df_to_merge[\"Date\"] >= pd.Period(\"1990-12\", freq=\"M\")].copy()\n",
    "    df_to_merge.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if col not in monthly_covariates.columns:\n",
    "        print(f\"{col} merged into monthly_df\")\n",
    "        monthly_covariates = monthly_covariates.merge(\n",
    "            df_to_merge[[\"Ticker\", \"Date\", col]],\n",
    "            how=\"left\",\n",
    "            on=[\"Ticker\", \"Date\"]\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{col} already in monthly_covariates — skipping.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monthly_from_yearly\n",
    "# Merge avec yearly_cov\n",
    "\n",
    "for col in yearly_cov.columns:\n",
    "    if col not in monthly_covariates.columns:\n",
    "        monthly_covariates = pd.merge(monthly_covariates, yearly_cov, on=[\"Ticker\", \"Date\"], how=\"left\")\n",
    "        print(f\"{col} merged into monthly_covariates\")\n",
    "    else:\n",
    "        print(f\"{col} already in monthly_covariates — skipping.\")\n",
    "\n",
    "# Merge monthly_nincr\n",
    "for col in monthly_nincr_df.columns:\n",
    "    if col not in [\"Ticker\", \"Date\"]:\n",
    "        if col not in monthly_covariates.columns:\n",
    "            monthly_covariates = pd.merge(monthly_covariates, monthly_nincr_df, on=[\"Ticker\", \"Date\"], how=\"left\")\n",
    "            print(f\"{col} merged into monthly_covariates\")\n",
    "        else:\n",
    "            print(f\"{col} already in monthly_covariates — skipping.\")\n",
    "\n",
    "#merge avec excess returns \n",
    "for col in df_excess_return.columns:\n",
    "    if col not in [\"Ticker\", \"Date\"]:\n",
    "        if col not in monthly_covariates.columns:\n",
    "            monthly_covariates = pd.merge(monthly_covariates, df_excess_return, on=[\"Ticker\", \"Date\"], how=\"left\")\n",
    "            print(f\"{col} merged into monthly_covariates\")\n",
    "        else:\n",
    "            print(f\"{col} already in monthly_covariates — skipping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste des covariables à normaliser\n",
    "covariates = [\"dolvol_lag2\", \"maxret\", \"retvol\", \"mom36m\", \"mom12m\", \"mom6m\", \"mom1m\", \"chmom\", \"turn\", \n",
    "\"indmom\", \"baspread\", \"illiq\", \"stdturn\", \"beta\", \"beta_squared\", \"idiovol\", \"mvel1\"]\n",
    "\n",
    "for cov in covariates:\n",
    "    monthly_covariates[f'{cov}_norm'] = np.nan\n",
    "\n",
    "for date_key in monthly_covariates['Date'].unique():\n",
    "    group = monthly_covariates[monthly_covariates['Date'] == date_key]\n",
    "    idx = group.index\n",
    "    for cov in covariates:\n",
    "        temp = group[[cov]].sort_values(by=cov).dropna()\n",
    "        n = len(temp)\n",
    "        if n == 1:\n",
    "            scores = [0]\n",
    "        else:\n",
    "            scores = 2 * np.arange(n) / (n - 1) - 1\n",
    "        monthly_covariates.loc[temp.index, f'{cov}_norm'] = scores\n",
    "\n",
    "df_final = monthly_covariates[['Date', 'Ticker'] + [f'{cov}_norm' for cov in covariates]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_excel(\"data/processed/df_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git-filter-repo\n",
      "  Downloading git_filter_repo-2.47.0-py3-none-any.whl.metadata (31 kB)\n",
      "Downloading git_filter_repo-2.47.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: git-filter-repo\n",
      "Successfully installed git-filter-repo-2.47.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script git-filter-repo.exe is installed in 'c:\\Users\\33676\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install git-filter-repo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
