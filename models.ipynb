{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c5a0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316805c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_excel(\"data/processed/df_final_norm.xlsx\")\n",
    "df_final = df_final.sort_values(\"Date\").reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee264fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FONCTIONS \n",
    "\n",
    "def generate_time_splits(df, date_col='Date', train_ratio=0.85, step_months=12, val_months=12, test_months=12):\n",
    "    \"\"\"\n",
    "    Génère des splits temporels rolling window : train / val / test\n",
    "\n",
    "    Paramètres :\n",
    "    - df : df trié par date\n",
    "    - date_col : nom de la colonne des dates\n",
    "    - train_ratio : part du dataset à allouer au train initial (ex: 0.85)\n",
    "    - step_months : taille du pas de glissement (ex: 12)\n",
    "    - val_months : taille de la validation (ex: 12)\n",
    "    - test_months : taille du test (ex: 12)\n",
    "\n",
    "    Retour :\n",
    "    - liste de tuples (train_idx, val_idx, test_idx)\n",
    "    \"\"\"\n",
    "    df = df.sort_values(date_col).reset_index(drop=True)\n",
    "    dates = sorted(df[date_col].unique())\n",
    "    total_months = len(dates)\n",
    "    train_initial = int(total_months * train_ratio)\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    for i in range(0, total_months - train_initial - val_months - test_months + 1, step_months):\n",
    "        train_end = train_initial + i\n",
    "        val_start = train_end\n",
    "        val_end = val_start + val_months\n",
    "        test_start = val_end\n",
    "        test_end = test_start + test_months\n",
    "\n",
    "        if test_end > total_months:\n",
    "            break\n",
    "\n",
    "        train_dates = dates[:train_end]\n",
    "        val_dates = dates[val_start:val_end]\n",
    "        test_dates = dates[test_start:test_end]\n",
    "\n",
    "        train_idx = df[df[date_col].isin(train_dates)].index.tolist()\n",
    "        val_idx = df[df[date_col].isin(val_dates)].index.tolist()\n",
    "        test_idx = df[df[date_col].isin(test_dates)].index.tolist()\n",
    "\n",
    "        splits.append((train_idx, val_idx, test_idx))\n",
    "    return splits \n",
    "\n",
    "\n",
    "#exclude cols\n",
    "exclude_cols = [\"Ticker\", \"Date\", \"excess_return\"]\n",
    "def get_X_y(df, idx, target=\"excess_return\", exclude_cols=None):\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = [\"Ticker\", \"Date\", target]\n",
    "    subset = df.loc[idx]\n",
    "    x = subset.drop(columns=exclude_cols)\n",
    "    y = subset[target]\n",
    "    return x, y\n",
    "\n",
    "#PLS \n",
    "def pls_tuning(X_train, y_train, X_val, y_val, X_test, y_test, max_components=28):\n",
    "    \"\"\"\n",
    "    Tuning et estimation du modèle PLS selon Gu et al. (2020)\n",
    "    \"\"\"\n",
    "    candidate_ks = np.arange(1, min(max_components, X_train.shape[1]) + 1) #test de 1 à 28 composants \n",
    "    mse_val_grid = []\n",
    "\n",
    "    for k in candidate_ks:\n",
    "\n",
    "        #entraîne sur train \n",
    "        model = PLSRegression(n_components=k, scale=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds_val = model.predict(X_val).ravel()\n",
    "        mse = mean_squared_error(y_val, preds_val)\n",
    "        mse_val_grid.append(mse)\n",
    "    #meilleur k : minimise MSE \n",
    "    best_k = candidate_ks[np.argmin(mse_val_grid)]\n",
    "\n",
    "    # Réentraînement sur train + val\n",
    "    X_trainval = pd.concat([X_train, X_val])\n",
    "    y_trainval = pd.concat([y_train, y_val])\n",
    "    model_final = PLSRegression(n_components=best_k, scale=False)\n",
    "    model_final.fit(X_trainval, y_trainval)\n",
    "\n",
    "    preds_test = model_final.predict(X_test).ravel()\n",
    "    r2_test = 1 - np.sum((y_test - preds_test)**2) / np.sum(y_test**2)\n",
    "\n",
    "    return preds_test, best_k, mse_val_grid, r2_test\n",
    "\n",
    "#PCR\n",
    "\n",
    "def pcr_tuning(X_train, y_train, X_val, y_val, X_test, y_test, max_components=28):\n",
    "    \"\"\"\n",
    "    Tuning et estimation du modèle PCR (Principal Component Regression)\n",
    "    \"\"\"\n",
    "    candidate_ks = np.arange(1, min(max_components, X_train.shape[1]) + 1)\n",
    "    mse_val_grid = []\n",
    "\n",
    "    for k in candidate_ks:\n",
    "        pca = PCA(n_components=k)\n",
    "        pca.fit(X_train)\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        X_val_pca = pca.transform(X_val)\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_pca, y_train)\n",
    "        preds_val = model.predict(X_val_pca).ravel()\n",
    "        mse = mean_squared_error(y_val, preds_val)\n",
    "        mse_val_grid.append(mse)\n",
    "\n",
    "    # Meilleur k : minimise le MSE\n",
    "    best_k = candidate_ks[np.argmin(mse_val_grid)]\n",
    "\n",
    "    # Réentraînement sur train + val\n",
    "    X_trainval = pd.concat([X_train, X_val])\n",
    "    y_trainval = pd.concat([y_train, y_val])\n",
    "    pca_final = PCA(n_components=best_k)\n",
    "    X_trainval_pca = pca_final.fit_transform(X_trainval)\n",
    "    model_final = LinearRegression()\n",
    "    model_final.fit(X_trainval_pca, y_trainval)\n",
    "\n",
    "    # Prédictions sur test\n",
    "    X_test_pca = pca_final.transform(X_test)\n",
    "    preds_test = model_final.predict(X_test_pca).ravel()\n",
    "    r2_test = 1 - np.sum((y_test - preds_test)**2) / np.sum(y_test**2)\n",
    "\n",
    "    return preds_test, best_k, mse_val_grid, r2_test\n",
    "\n",
    "def enet_tuning(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "                      alpha_grid=None, l1_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Tuning et estimation du modèle ElasticNet (Huber loss) sans standardisation,\n",
    "    en supposant que les données ont déjà été normalisées entre -1 et 1.\n",
    "    \"\"\"\n",
    "    if alpha_grid is None:\n",
    "        alpha_grid = np.logspace(10E-5, -10E-1, num=20)\n",
    "\n",
    "    mse_val_grid = []\n",
    "\n",
    "    for alpha in alpha_grid:\n",
    "        model = SGDRegressor(loss='huber',\n",
    "                             penalty='elasticnet',\n",
    "                             alpha=alpha,\n",
    "                             l1_ratio=l1_ratio,\n",
    "                             max_iter=1000,\n",
    "                             tol=1e-3,\n",
    "                             random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds_val = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, preds_val)\n",
    "        mse_val_grid.append(mse)\n",
    "\n",
    "    best_alpha = alpha_grid[np.argmin(mse_val_grid)]\n",
    "\n",
    "    # Réentraînement sur train + val\n",
    "    X_trainval = pd.concat([X_train, X_val])\n",
    "    y_trainval = pd.concat([y_train, y_val])\n",
    "    model_final = SGDRegressor(loss='huber',\n",
    "                               penalty='elasticnet',\n",
    "                               alpha=best_alpha,\n",
    "                               l1_ratio=l1_ratio,\n",
    "                               max_iter=1000,\n",
    "                               tol=1e-3,\n",
    "                               random_state=42)\n",
    "    model_final.fit(X_trainval, y_trainval)\n",
    "\n",
    "    # Prédictions sur test\n",
    "    preds_test = model_final.predict(X_test)\n",
    "    r2_test = 1 - np.sum((y_test - preds_test)**2) / np.sum(y_test**2)\n",
    "\n",
    "    return preds_test, best_alpha, mse_val_grid, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6e857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITS : 85% de la data, rolling tous les 12 ans\n",
    "\n",
    "splits = generate_time_splits(df_final, date_col=\"Date\", train_ratio=0.85, step_months=12, val_months=12, test_months=12)\n",
    "\n",
    "\n",
    "# Résultats PLS\n",
    "y_preds_pls = []\n",
    "y_test_pls = []\n",
    "dates_pls = []\n",
    "r2_by_date = []\n",
    "best_k_by_date = []\n",
    "\n",
    "# Résultats OLS\n",
    "y_preds_ols = []\n",
    "y_test_ols = []\n",
    "dates_ols = []\n",
    "r2_by_date_ols = []\n",
    "\n",
    "# Résultats PCR\n",
    "y_preds_pcr = []\n",
    "y_test_pcr = []\n",
    "dates_pcr = []\n",
    "r2_by_date_pcr = []\n",
    "best_k_by_date_pcr = []\n",
    "\n",
    "#Elastic Net\n",
    "y_preds_enh = []\n",
    "y_test_enh = []\n",
    "dates_enh = []\n",
    "r2_by_date_enh = []\n",
    "best_alpha_by_date_enh = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8753fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:32<00:00, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² OOS global PLS : 0.0253\n",
      "R² OOS global OLS : 0.0263\n",
      "R² OOS global PCR : 0.0237\n",
      "R² OOS global ENH : -0.1376\n",
      "Best alpha (ENH) pour la fenêtre : 0.886060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear models \n",
    "\n",
    "for train_idx, val_idx, test_idx in tqdm(splits):\n",
    "    X_train, y_train = get_X_y(df_final, train_idx)\n",
    "    X_val, y_val = get_X_y(df_final, val_idx)\n",
    "    X_test, y_test = get_X_y(df_final, test_idx)\n",
    "\n",
    "    #OLS\n",
    "    X_trainval = pd.concat([X_train, X_val])\n",
    "    y_trainval = pd.concat([y_train, y_val])\n",
    "    model_ols = LinearRegression()\n",
    "    model_ols.fit(X_trainval, y_trainval)\n",
    "    preds_test_ols = model_ols.predict(X_test)\n",
    "    r2_test_ols = 1 - np.sum((y_test - preds_test_ols)**2) / np.sum(y_test**2) if np.sum(y_test**2) > 0 else np.nan\n",
    "    y_preds_ols.append(preds_test_ols)\n",
    "    y_test_ols.append(y_test.values)\n",
    "    dates_ols.append(df_final.loc[test_idx, \"Date\"].values)\n",
    "    r2_by_date_ols.append(r2_test_ols)\n",
    "\n",
    "\n",
    "    #PLS\n",
    "    preds_test, best_k, mse_grid, r2_test = pls_tuning(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    y_preds_pls.append(preds_test)\n",
    "    y_test_pls.append(y_test.values)\n",
    "    dates_pls.append(df_final.loc[test_idx, \"Date\"].values)\n",
    "    r2_by_date.append(r2_test)\n",
    "    best_k_by_date.append(best_k)\n",
    "\n",
    "\n",
    "    # PCR\n",
    "    preds_test_pcr, best_k_pcr, _, r2_test_pcr = pcr_tuning(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    y_preds_pcr.append(preds_test_pcr)\n",
    "    y_test_pcr.append(y_test.values)\n",
    "    dates_pcr.append(df_final.loc[test_idx, \"Date\"].values)\n",
    "    r2_by_date_pcr.append(r2_test_pcr)\n",
    "    best_k_by_date_pcr.append(best_k_pcr)\n",
    "\n",
    "    #Elastic Net\n",
    "    preds_test_enh, best_alpha_enh, _, r2_test_enh = enet_tuning(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    y_preds_enh.append(preds_test_enh)\n",
    "    y_test_enh.append(y_test.values)\n",
    "    dates_enh.append(df_final.loc[test_idx, \"Date\"].values)\n",
    "    r2_by_date_enh.append(r2_test_enh)\n",
    "    best_alpha_by_date_enh.append(best_alpha_enh)\n",
    "\n",
    "\n",
    " \n",
    "# --- R² OOS global PLS\n",
    "y_preds_all = np.concatenate(y_preds_pls)\n",
    "y_test_all = np.concatenate(y_test_pls)\n",
    "dates_all = np.concatenate(dates_pls)\n",
    "R2OOS_PLS = 1 - np.sum((y_test_all - y_preds_all) ** 2) / np.sum(y_test_all ** 2)\n",
    "print(f\"R² OOS global PLS : {R2OOS_PLS:.4f}\")\n",
    "\n",
    "# --- R² OOS global OLS\n",
    "y_preds_ols_all = np.concatenate(y_preds_ols)\n",
    "y_test_ols_all = np.concatenate(y_test_ols)\n",
    "R2OOS_OLS = 1 - np.sum((y_test_ols_all - y_preds_ols_all) ** 2) / np.sum(y_test_ols_all ** 2)\n",
    "print(f\"R² OOS global OLS : {R2OOS_OLS:.4f}\")\n",
    "\n",
    "# --- R² OOS global PCR\n",
    "y_preds_all_pcr = np.concatenate(y_preds_pcr)\n",
    "y_test_all_pcr = np.concatenate(y_test_pcr)\n",
    "R2OOS_PCR = 1 - np.sum((y_test_all_pcr - y_preds_all_pcr) ** 2) / np.sum(y_test_all_pcr ** 2)\n",
    "print(f\"R² OOS global PCR : {R2OOS_PCR:.4f}\")\n",
    "\n",
    "#Enet \n",
    "y_preds_enh_all = np.concatenate(y_preds_enh)\n",
    "y_test_enh_all = np.concatenate(y_test_enh)\n",
    "dates_enh_all = np.concatenate(dates_enh)\n",
    "R2OOS_ENH = 1 - np.sum((y_test_enh_all - y_preds_enh_all) ** 2) / np.sum(y_test_enh_all ** 2)\n",
    "print(f\"R² OOS global ENH : {R2OOS_ENH:.4f}\")\n",
    "print(f\"Best alpha (ENH) pour la fenêtre : {best_alpha_enh:.6f}\")\n",
    "\n",
    "# --- Résultats détaillés tout\n",
    "df_r2 = pd.DataFrame({\n",
    "    \"date\": [d[0] for d in dates_pls],\n",
    "    \"R2_test_pls\": r2_by_date,\n",
    "    \"Best_k_pls\": best_k_by_date,\n",
    "    \"R2_test_ols\": r2_by_date_ols,\n",
    "    \"R2_test_pcr\": r2_by_date_pcr,\n",
    "    \"Best_k_pcr\": best_k_by_date_pcr,\n",
    "    \"best_alpha_by_date_enh\" : best_alpha_by_date_enh\n",
    "})\n",
    "\n",
    "df_preds = pd.DataFrame({\n",
    "    \"date\": np.concatenate(dates_pls),\n",
    "    \"y_test\": y_test_all,\n",
    "    \"y_pred_ols\": y_preds_ols_all,\n",
    "    \"y_pred_pls\": y_preds_all,\n",
    "    \"y_pred_pcr\": y_preds_all_pcr,\n",
    "    \"y_pred_enh\": y_preds_enh_all\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076744ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyse PLS ---\n",
      "Moyenne y_test : 0.008396\n",
      "Moyenne prédictions : 0.012086\n",
      "MSE : 0.006309\n",
      "MAE : 0.058339\n",
      "Écart-type des erreurs : 0.079342\n",
      "Erreur moyenne : 0.003689\n",
      "Min préd : -0.029126 | Max préd : 0.070661\n",
      "Min vrai : -0.592751 | Max vrai : 0.532851\n",
      "\n",
      "--- Analyse OLS ---\n",
      "Moyenne y_test : 0.008396\n",
      "Moyenne prédictions : 0.012073\n",
      "MSE : 0.006302\n",
      "MAE : 0.058370\n",
      "Écart-type des erreurs : 0.079301\n",
      "Erreur moyenne : 0.003677\n",
      "Min préd : -0.036832 | Max préd : 0.070653\n",
      "Min vrai : -0.592751 | Max vrai : 0.532851\n",
      "\n",
      "--- Analyse PCR ---\n",
      "Moyenne y_test : 0.008396\n",
      "Moyenne prédictions : 0.012082\n",
      "MSE : 0.006319\n",
      "MAE : 0.058399\n",
      "Écart-type des erreurs : 0.079410\n",
      "Erreur moyenne : 0.003686\n",
      "Min préd : -0.029209 | Max préd : 0.070653\n",
      "Min vrai : -0.592751 | Max vrai : 0.532851\n",
      "\n",
      "--- Analyse ElasticNet ---\n",
      "Moyenne y_test : 0.008396\n",
      "Moyenne prédictions : 0.038939\n",
      "MSE : 0.007363\n",
      "MAE : 0.064016\n",
      "Écart-type des erreurs : 0.080189\n",
      "Erreur moyenne : 0.030543\n",
      "Min préd : 0.033017 | Max préd : 0.047358\n",
      "Min vrai : -0.592751 | Max vrai : 0.532851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def analyse_modele(y_test_all, y_preds_all, nom_modele):\n",
    "    erreur = y_preds_all - y_test_all\n",
    "    print(f\"\\n--- Analyse {nom_modele} ---\")\n",
    "    print(f\"Moyenne y_test : {np.mean(y_test_all):.6f}\")\n",
    "    print(f\"Moyenne prédictions : {np.mean(y_preds_all):.6f}\")\n",
    "    print(f\"MSE : {mean_squared_error(y_test_all, y_preds_all):.6f}\")\n",
    "    print(f\"MAE : {mean_absolute_error(y_test_all, y_preds_all):.6f}\")\n",
    "    print(f\"Écart-type des erreurs : {np.std(erreur):.6f}\")\n",
    "    print(f\"Erreur moyenne : {np.mean(erreur):.6f}\")\n",
    "    print(f\"Min préd : {np.min(y_preds_all):.6f} | Max préd : {np.max(y_preds_all):.6f}\")\n",
    "    print(f\"Min vrai : {np.min(y_test_all):.6f} | Max vrai : {np.max(y_test_all):.6f}\")\n",
    "\n",
    "analyse_modele(y_test_all, y_preds_all, \"PLS\")\n",
    "analyse_modele(y_test_ols_all, y_preds_ols_all, \"OLS\")\n",
    "analyse_modele(y_test_all_pcr, y_preds_all_pcr, \"PCR\")\n",
    "analyse_modele(y_test_enh_all, y_preds_enh_all, \"ElasticNet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5396a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [03:35<00:00, 71.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² OOS global RF : 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Fonction de tuning RF\n",
    "def rf_tuning(X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "              n_estimators_list=[100, 300],\n",
    "              max_depth_list=[10, 20, None],\n",
    "              min_samples_leaf_list=[1, 5],\n",
    "              max_features_list=['sqrt', 'log2']):\n",
    "\n",
    "    best_mse = np.inf\n",
    "    best_params = None\n",
    "\n",
    "    for n in n_estimators_list:\n",
    "        for d in max_depth_list:\n",
    "            for leaf in min_samples_leaf_list:\n",
    "                for feat in max_features_list:\n",
    "                    model = RandomForestRegressor(\n",
    "                        n_estimators=n,\n",
    "                        max_depth=d,\n",
    "                        min_samples_leaf=leaf,\n",
    "                        max_features=feat,\n",
    "                        random_state=42,\n",
    "                        n_jobs=-1\n",
    "                    )\n",
    "                    model.fit(X_train, y_train)\n",
    "                    preds_val = model.predict(X_val)\n",
    "                    mse = mean_squared_error(y_val, preds_val)\n",
    "\n",
    "                    if mse < best_mse:\n",
    "                        best_mse = mse\n",
    "                        best_params = (n, d, leaf, feat)\n",
    "\n",
    "    # Réentraînement sur train + val\n",
    "    X_trainval = pd.concat([X_train, X_val])\n",
    "    y_trainval = pd.concat([y_train, y_val])\n",
    "    model_final = RandomForestRegressor(\n",
    "        n_estimators=best_params[0],\n",
    "        max_depth=best_params[1],\n",
    "        min_samples_leaf=best_params[2],\n",
    "        max_features=best_params[3],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model_final.fit(X_trainval, y_trainval)\n",
    "    preds_test = model_final.predict(X_test)\n",
    "    r2_test = 1 - np.sum((y_test - preds_test)**2) / np.sum(y_test**2) if np.sum(y_test**2) > 0 else np.nan\n",
    "\n",
    "    return preds_test, best_params, r2_test\n",
    "\n",
    "\n",
    "y_preds_rf = []\n",
    "y_test_rf = []\n",
    "dates_rf = []\n",
    "r2_by_date_rf = []\n",
    "best_params_by_date_rf = []\n",
    "\n",
    "# --- Génération des splits\n",
    "splits = generate_time_splits(df_final, date_col=\"Date\", train_ratio=0.85, step_months=12, val_months=12, test_months=12)\n",
    "\n",
    "# --- Boucle principale RF\n",
    "for train_idx, val_idx, test_idx in tqdm(splits):\n",
    "    X_train, y_train = get_X_y(df_final, train_idx)\n",
    "    X_val, y_val = get_X_y(df_final, val_idx)\n",
    "    X_test, y_test = get_X_y(df_final, test_idx)\n",
    "\n",
    "    preds_test_rf, best_params_rf, r2_test_rf = rf_tuning(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "    y_preds_rf.append(preds_test_rf)\n",
    "    y_test_rf.append(y_test.values)\n",
    "    dates_rf.append(df_final.loc[test_idx, \"Date\"].values)\n",
    "    r2_by_date_rf.append(r2_test_rf)\n",
    "    best_params_by_date_rf.append(best_params_rf)\n",
    "\n",
    "# --- R² OOS global RF\n",
    "y_preds_rf_all = np.concatenate(y_preds_rf)\n",
    "y_test_rf_all = np.concatenate(y_test_rf)\n",
    "R2OOS_RF = 1 - np.sum((y_test_rf_all - y_preds_rf_all) ** 2) / np.sum(y_test_rf_all ** 2)\n",
    "print(f\"R² OOS global RF : {R2OOS_RF:.4f}\")\n",
    "\n",
    "# --- Résultats dans df\n",
    "df_r2_rf = pd.DataFrame({\n",
    "    \"date\": [d[0] for d in dates_rf],\n",
    "    \"R2_test_rf\": r2_by_date_rf,\n",
    "    \"best_params_rf\": best_params_by_date_rf\n",
    "})\n",
    "\n",
    "df_preds_rf = pd.DataFrame({\n",
    "    \"date\": np.concatenate(dates_rf),\n",
    "    \"y_test\": y_test_rf_all,\n",
    "    \"y_pred_rf\": y_preds_rf_all\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae28829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyse Random Forest ---\n",
      "Moyenne y_test : 0.008396\n",
      "Moyenne prédictions : 0.010733\n",
      "MSE : 0.006265\n",
      "MAE : 0.058155\n",
      "Écart-type des erreurs : 0.079117\n",
      "Erreur moyenne : 0.002337\n",
      "Min préd : -0.041196 | Max préd : 0.048767\n",
      "Min vrai : -0.592751 | Max vrai : 0.532851\n"
     ]
    }
   ],
   "source": [
    "analyse_modele(y_test_rf_all, y_preds_rf_all, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c5ae896",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_in_ols = []\n",
    "r2_in_pls = []\n",
    "r2_in_pcr = []\n",
    "r2_in_enh = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d09c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # concaténation train + val\n",
    "    X_trainval = pd.concat([X_train, X_val])\n",
    "    y_trainval = pd.concat([y_train, y_val])\n",
    "\n",
    "    # R² in-sample naïf OLS\n",
    "    y_in_ols = model_ols.predict(X_trainval)\n",
    "    r2_in_ols.append(1 - np.mean((y_trainval - y_in_ols) ** 2) / np.var(y_trainval))\n",
    "\n",
    "    # R² in-sample naïf PLS\n",
    "    pls_model_in = PLSRegression(n_components=best_k, scale=False)\n",
    "    pls_model_in.fit(X_trainval, y_trainval)\n",
    "    y_in_pls = pls_model_in.predict(X_trainval).ravel()\n",
    "    r2_in_pls.append(1 - np.mean((y_trainval - y_in_pls) ** 2) / np.var(y_trainval))\n",
    "\n",
    "    # R² in-sample naïf PCR\n",
    "    pca_in = PCA(n_components=best_k_pcr)\n",
    "    X_trainval_pca = pca_in.fit_transform(X_trainval)\n",
    "    model_pcr_in = LinearRegression().fit(X_trainval_pca, y_trainval)\n",
    "    y_in_pcr = model_pcr_in.predict(X_trainval_pca)\n",
    "    r2_in_pcr.append(1 - np.mean((y_trainval - y_in_pcr) ** 2) / np.var(y_trainval))\n",
    "\n",
    "    # R² in-sample naïf ENH\n",
    "    model_enh_in = SGDRegressor(loss='huber',\n",
    "                                penalty='elasticnet',\n",
    "                                alpha=best_alpha_enh,\n",
    "                                l1_ratio=0.5,\n",
    "                                max_iter=1000,\n",
    "                                tol=1e-3,\n",
    "                                random_state=42)\n",
    "    model_enh_in.fit(X_trainval, y_trainval)\n",
    "    y_in_enh = model_enh_in.predict(X_trainval)\n",
    "    r2_in_enh.append(1 - np.mean((y_trainval - y_in_enh) ** 2) / np.var(y_trainval))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² in-sample OLS (naïf): 0.0206\n",
      "R² in-sample PLS (naïf): 0.0206\n",
      "R² in-sample PCR (naïf): 0.0206\n",
      "R² in-sample ENH (naïf): -0.0730\n"
     ]
    }
   ],
   "source": [
    "print(f\"R² in-sample OLS (naïf): {np.mean(r2_in_ols):.4f}\")\n",
    "print(f\"R² in-sample PLS (naïf): {np.mean(r2_in_pls):.4f}\")\n",
    "print(f\"R² in-sample PCR (naïf): {np.mean(r2_in_pcr):.4f}\")\n",
    "print(f\"R² in-sample ENH (naïf): {np.mean(r2_in_enh):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e954c5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables les plus corrélées :\n",
      "\n",
      "beta          beta_squared    1.000000\n",
      "beta_squared  beta            1.000000\n",
      "illiq         dolvol_lag2     0.907136\n",
      "dolvol_lag2   illiq           0.907136\n",
      "illiq         mvel1           0.884901\n",
      "mvel1         illiq           0.884901\n",
      "stdturn       turn            0.814659\n",
      "turn          stdturn         0.814659\n",
      "mvel1         dolvol_lag2     0.807527\n",
      "dolvol_lag2   mvel1           0.807527\n",
      "retvol        maxret          0.803178\n",
      "maxret        retvol          0.803178\n",
      "invest        chinv           0.654425\n",
      "chinv         invest          0.654425\n",
      "idiovol       turn            0.648615\n",
      "turn          idiovol         0.648615\n",
      "retvol        idiovol         0.626190\n",
      "idiovol       retvol          0.626190\n",
      "retvol        turn            0.610341\n",
      "turn          retvol          0.610341\n",
      "beta          retvol          0.609475\n",
      "retvol        beta_squared    0.609475\n",
      "beta_squared  retvol          0.609475\n",
      "retvol        beta            0.609475\n",
      "chmom         mom6m           0.608613\n",
      "mom6m         chmom           0.608613\n",
      "mom12m        mom6m           0.607710\n",
      "mom6m         mom12m          0.607710\n",
      "turn          beta            0.598327\n",
      "beta          turn            0.598327\n",
      "beta_squared  turn            0.598327\n",
      "turn          beta_squared    0.598327\n",
      "idiovol       beta            0.583528\n",
      "beta_squared  idiovol         0.583528\n",
      "idiovol       beta_squared    0.583528\n",
      "beta          idiovol         0.583528\n",
      "stdturn       idiovol         0.569036\n",
      "idiovol       stdturn         0.569036\n",
      "agr           invest          0.564920\n",
      "invest        agr             0.564920\n",
      "cashpr        sp              0.536746\n",
      "sp            cashpr          0.536746\n",
      "maxret        idiovol         0.515274\n",
      "idiovol       maxret          0.515274\n",
      "beta          maxret          0.512095\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcul de la matrice de corrélation\n",
    "corr_matrix = X_trainval.corr()\n",
    "\n",
    "# Affichage rapide : top 10 paires les plus corrélées (hors diagonale)\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]\n",
    "corr_pairs = corr_pairs.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"variables les plus corrélées :\\n\")\n",
    "print(corr_pairs.head(45))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "add99cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [03:53<00:00, 77.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² in-sample moyen RF : 0.2808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r2_in_rf = []  # liste pour stocker les R² in-sample par split\n",
    "\n",
    "for train_idx, val_idx, test_idx in tqdm(splits):\n",
    "    X_train, y_train = get_X_y(df_final, train_idx)\n",
    "    X_val, y_val = get_X_y(df_final, val_idx)\n",
    "    X_test, y_test = get_X_y(df_final, test_idx)\n",
    "\n",
    "    # tuning sur train/val/test\n",
    "    preds_test_rf, best_params_rf, r2_test_rf = rf_tuning(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "    # --- R² in-sample naïf RF (sur train+val)\n",
    "    X_trainval = pd.concat([X_train, X_val])\n",
    "    y_trainval = pd.concat([y_train, y_val])\n",
    "    model_rf_in = RandomForestRegressor(\n",
    "        n_estimators=best_params_rf[0],\n",
    "        max_depth=best_params_rf[1],\n",
    "        min_samples_leaf=best_params_rf[2],\n",
    "        max_features=best_params_rf[3],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model_rf_in.fit(X_trainval, y_trainval)\n",
    "    y_in_rf = model_rf_in.predict(X_trainval)\n",
    "    r2_val = 1 - np.mean((y_trainval - y_in_rf) ** 2) / np.var(y_trainval)\n",
    "    r2_in_rf.append(r2_val)\n",
    "\n",
    "    # --- (le reste de ton stockage pour OOS)\n",
    "    y_preds_rf.append(preds_test_rf)\n",
    "    y_test_rf.append(y_test.values)\n",
    "    dates_rf.append(df_final.loc[test_idx, \"Date\"].values)\n",
    "    r2_by_date_rf.append(r2_test_rf)\n",
    "    best_params_by_date_rf.append(best_params_rf)\n",
    "\n",
    "# après la boucle :\n",
    "print(f\"R² in-sample moyen RF : {np.mean(r2_in_rf):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
